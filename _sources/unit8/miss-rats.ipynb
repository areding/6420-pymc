{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63309b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from pymc.math import dot, stack, concatenate, exp, invlogit, logit\n",
    "\n",
    "%load_ext lab_black\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa33d9",
   "metadata": {},
   "source": [
    "# Rats\n",
    "\n",
    "This example goes further into dealing with missing data in PyMC, including in the predictor variables.\n",
    "\n",
    "Adapted from [Unit 8: ratsignorable1.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsignorable1.odc), [ratsignorable2.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsignorable2.odc), and [ratsinformative.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsinformative.odc).\n",
    "\n",
    "Data can be found [here](https://raw.githubusercontent.com/areding/6420-pymc/main/data/rats.txt).\n",
    "\n",
    "Associated lecture videos: Unit 8 lesson 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a80d0a",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "We had a previous example about [Dugongs](https://areding.github.io/6420-pymc/Unit6-dugongs.html) that dealt with missing data in the observed data (y values). This example shows how to deal with missing data in the input data (x). It's still pretty easy. You could look at it like creating another likelihood in the model, a very simple one where the observed data is x, and you use a single distribution to fill in the missing values (see ```x_imputed``` in the model below).\n",
    "\n",
    "Original paper [here.](https://www.jstor.org/stable/pdf/2289594.pdf)\n",
    "\n",
    "Gelfand et al 1990 consider the problem of missing data, and delete the last observation of cases 6-10, the last two from 11-20, the last 3 from 21-25 and the last 4 from 26-30.  The appropriate data file is obtained by simply replacing data values by NA (see below). The model specification is unchanged, since the distinction between observed and unobserved quantities is made in the data file and not the model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bff621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([8.0, 15.0, 22.0, 29.0, 36.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d405a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import y data and create mask (missing data is represented as nan in the file)\n",
    "y = np.loadtxt(\"../data/rats.txt\")\n",
    "y = np.nan_to_num(y, nan=-1)  # nan to -1\n",
    "y = np.ma.masked_values(y, value=-1)  # create mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf67ff-c761-4106-ba98-20d755cf5631",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "This first model we only have missing data in our response variable (y). Notice that I made the shapes of alpha and beta (30, 1) instead of just 30. This is so that they broadcast correctly when combined (```mu = alpha + beta * x```). The NumPy docs have a helpful [page about broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddac632e",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/pymc/model.py:1431: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_c, alpha_tau, beta_c, beta_tau, alpha, beta, lik_tau, likelihood_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='24000' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24000/24000 02:23&lt;00:00 Sampling 4 chains, 14 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 153 seconds.\n",
      "There were 14 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    alpha_c = pm.Normal(\"alpha_c\", 0, tau=1e-6)\n",
    "    alpha_tau = pm.Gamma(\"alpha_tau\", 0.001, 0.001)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, tau=1e-6)\n",
    "    beta_tau = pm.Gamma(\"beta_tau\", 0.001, 0.001)\n",
    "\n",
    "    alpha = pm.Normal(\n",
    "        \"alpha\", alpha_c, tau=alpha_tau, shape=(30, 1)\n",
    "    )  # (30, 1) for broadcasting\n",
    "    beta = pm.Normal(\"beta\", beta_c, tau=beta_tau, shape=(30, 1))\n",
    "    lik_tau = pm.Gamma(\"lik_tau\", 0.001, 0.001)\n",
    "    sigma = pm.Deterministic(\"sigma\", 1 / lik_tau**0.5)\n",
    "\n",
    "    mu = alpha + beta * x\n",
    "\n",
    "    pm.Normal(\"likelihood\", mu, tau=lik_tau, observed=y)\n",
    "\n",
    "    trace = pm.sample(\n",
    "        5000, tune=1000, cores=4, init=\"jitter+adapt_diag_grad\", target_accept=0.9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c215f8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_c</th>\n",
       "      <td>101.237</td>\n",
       "      <td>2.297</td>\n",
       "      <td>96.749</td>\n",
       "      <td>105.752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_tau</th>\n",
       "      <td>0.034</td>\n",
       "      <td>0.151</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_c</th>\n",
       "      <td>6.566</td>\n",
       "      <td>0.164</td>\n",
       "      <td>6.244</td>\n",
       "      <td>6.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_tau</th>\n",
       "      <td>2.884</td>\n",
       "      <td>1.245</td>\n",
       "      <td>0.966</td>\n",
       "      <td>5.276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>6.031</td>\n",
       "      <td>0.680</td>\n",
       "      <td>4.761</td>\n",
       "      <td>7.381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean     sd  hdi_2.5%  hdi_97.5%\n",
       "alpha_c    101.237  2.297    96.749    105.752\n",
       "alpha_tau    0.034  0.151     0.003      0.052\n",
       "beta_c       6.566  0.164     6.244      6.880\n",
       "beta_tau     2.884  1.245     0.966      5.276\n",
       "sigma        6.031  0.680     4.761      7.381"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(\n",
    "    trace,\n",
    "    hdi_prob=0.95,\n",
    "    var_names=[\"alpha_c\", \"alpha_tau\", \"beta_c\", \"beta_tau\", \"sigma\"],\n",
    "    kind=\"stats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5beaab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2: Imputing missing predictor variable data\n",
    "\n",
    "This is the same model, except we now have missing x data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc7494b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_miss = np.array([8.0, 15.0, 22.0, -1, 36.0])\n",
    "x_miss = np.ma.masked_values(x_miss, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f00743b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[8.0, 15.0, 22.0, --, 36.0],\n",
       "             mask=[False, False, False,  True, False],\n",
       "       fill_value=-1.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c4be27a",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/pymc/model.py:1431: ImputationWarning: Data in x_imputed contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/pymc/model.py:1431: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Auto-assigning NUTS sampler...\n",
      "INFO:pymc:Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "INFO:pymc:Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "INFO:pymc:Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_c, alpha_tau, beta_c, beta_tau, alpha, beta, lik_tau, x_imputed_missing, likelihood_missing]\n",
      "INFO:pymc:NUTS: [alpha_c, alpha_tau, beta_c, beta_tau, alpha, beta, lik_tau, x_imputed_missing, likelihood_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='24000' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24000/24000 01:48&lt;00:00 Sampling 4 chains, 7 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 117 seconds.\n",
      "INFO:pymc:Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 117 seconds.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 4 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    alpha_c = pm.Normal(\"alpha_c\", 0, tau=1e-6)\n",
    "    alpha_tau = pm.Gamma(\"alpha_tau\", 0.001, 0.001)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, tau=1e-6)\n",
    "    beta_tau = pm.Gamma(\"beta_tau\", 0.001, 0.001)\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", alpha_c, tau=alpha_tau, shape=(30, 1))\n",
    "    beta = pm.Normal(\"beta\", beta_c, tau=beta_tau, shape=(30, 1))\n",
    "    lik_tau = pm.Gamma(\"lik_tau\", 0.001, 0.001)\n",
    "    sigma = pm.Deterministic(\"sigma\", 1 / lik_tau**0.5)\n",
    "\n",
    "    x_imputed = pm.TruncatedNormal(\n",
    "        \"x_imputed\", mu=20, sigma=10, lower=0, observed=x_miss\n",
    "    )\n",
    "\n",
    "    mu = alpha + beta * x_imputed\n",
    "\n",
    "    pm.Normal(\"likelihood\", mu, tau=lik_tau, observed=y)\n",
    "\n",
    "    trace_2 = pm.sample(\n",
    "        5000, tune=1000, cores=4, init=\"jitter+adapt_diag_grad\", target_accept=0.9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "928b4518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_c</th>\n",
       "      <td>101.876</td>\n",
       "      <td>2.358</td>\n",
       "      <td>97.235</td>\n",
       "      <td>106.482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_c</th>\n",
       "      <td>6.509</td>\n",
       "      <td>0.167</td>\n",
       "      <td>6.179</td>\n",
       "      <td>6.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_tau</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_tau</th>\n",
       "      <td>3.001</td>\n",
       "      <td>1.278</td>\n",
       "      <td>0.932</td>\n",
       "      <td>5.438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lik_tau</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_imputed_missing[0]</th>\n",
       "      <td>29.500</td>\n",
       "      <td>0.385</td>\n",
       "      <td>28.754</td>\n",
       "      <td>30.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>5.970</td>\n",
       "      <td>0.654</td>\n",
       "      <td>4.791</td>\n",
       "      <td>7.307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean     sd  hdi_2.5%  hdi_97.5%\n",
       "alpha_c               101.876  2.358    97.235    106.482\n",
       "beta_c                  6.509  0.167     6.179      6.833\n",
       "alpha_tau               0.021  0.052     0.004      0.042\n",
       "beta_tau                3.001  1.278     0.932      5.438\n",
       "lik_tau                 0.029  0.006     0.017      0.041\n",
       "x_imputed_missing[0]   29.500  0.385    28.754     30.267\n",
       "sigma                   5.970  0.654     4.791      7.307"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(\n",
    "    trace_2,\n",
    "    hdi_prob=0.95,\n",
    "    var_names=[\"~alpha\", \"~beta\", \"~likelihood_missing\"],\n",
    "    kind=\"stats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b679604",
   "metadata": {},
   "source": [
    "## Model 3: Non-ignorable missingness\n",
    "\n",
    "Probability of missingness increases approx. at a rate of 1% with increasing the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06e3cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.atleast_2d(np.array([177.0, 236.0, 285.0, 350.0, -1]))  # original value was 320\n",
    "y = np.ma.masked_values(y, value=-1)  # create masked array\n",
    "# y.mask is equivalent to the \"miss\" array from the professor's example\n",
    "miss = y.mask\n",
    "x = np.array([8.0, 15.0, 22.0, 29.0, 36.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e747223d",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/pymc/model.py:1431: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Auto-assigning NUTS sampler...\n",
      "INFO:pymc:Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "INFO:pymc:Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "INFO:pymc:Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, alpha, beta, log_sigma, likelihood_missing]\n",
      "INFO:pymc:NUTS: [a, alpha, beta, log_sigma, likelihood_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='24000' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24000/24000 00:13&lt;00:00 Sampling 4 chains, 333 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 2_000 tune and 4_000 draw iterations (8_000 + 16_000 draws total) took 22 seconds.\n",
      "INFO:pymc:Sampling 4 chains for 2_000 tune and 4_000 draw iterations (8_000 + 16_000 draws total) took 22 seconds.\n",
      "There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 3 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 168 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 168 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.5763, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "WARNING:pymc:The acceptance probability does not match the target. It is 0.5763, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 86 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 86 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6707, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "WARNING:pymc:The acceptance probability does not match the target. It is 0.6707, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 76 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 76 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6872, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "WARNING:pymc:The acceptance probability does not match the target. It is 0.6872, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    }
   ],
   "source": [
    "t = 0.1\n",
    "s = 1 / t  # convert BUGS dlogis tau to s for pymc\n",
    "b = np.log(1.01)\n",
    "\n",
    "with pm.Model() as m:\n",
    "    a = pm.Logistic(\"a\", mu=0, s=s)\n",
    "    alpha = pm.Flat(\"alpha\")\n",
    "    beta = pm.Flat(\"beta\")\n",
    "    log_sigma = pm.Flat(\"log_sigma\")\n",
    "    sigma2 = pm.Deterministic(\"sigma2\", exp(2 * log_sigma))\n",
    "    tau = pm.Deterministic(\"tau\", 1 / sigma2)\n",
    "\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta * x)\n",
    "    y_imputed = pm.Normal(\"likelihood\", mu, tau=tau, observed=y)\n",
    "\n",
    "    p = pm.Deterministic(\"p\", invlogit(a + b * y_imputed))\n",
    "    pm.Bernoulli(\"missing\", p=p, observed=miss)\n",
    "\n",
    "    trace_3 = pm.sample(4000, tune=2000, init=\"jitter+adapt_diag_grad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3e39419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-4.861</td>\n",
       "      <td>1.447</td>\n",
       "      <td>-7.748</td>\n",
       "      <td>-2.315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>111.743</td>\n",
       "      <td>37.921</td>\n",
       "      <td>81.477</td>\n",
       "      <td>139.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>8.173</td>\n",
       "      <td>1.543</td>\n",
       "      <td>6.797</td>\n",
       "      <td>9.617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_sigma</th>\n",
       "      <td>1.857</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.776</td>\n",
       "      <td>3.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood_missing[0]</th>\n",
       "      <td>408.372</td>\n",
       "      <td>52.684</td>\n",
       "      <td>367.884</td>\n",
       "      <td>440.877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma2</th>\n",
       "      <td>1261.074</td>\n",
       "      <td>31508.011</td>\n",
       "      <td>3.312</td>\n",
       "      <td>569.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau</th>\n",
       "      <td>0.046</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[0]</th>\n",
       "      <td>177.124</td>\n",
       "      <td>29.071</td>\n",
       "      <td>155.395</td>\n",
       "      <td>193.343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[1]</th>\n",
       "      <td>234.333</td>\n",
       "      <td>24.006</td>\n",
       "      <td>220.789</td>\n",
       "      <td>244.858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[2]</th>\n",
       "      <td>291.542</td>\n",
       "      <td>23.254</td>\n",
       "      <td>279.611</td>\n",
       "      <td>304.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[3]</th>\n",
       "      <td>348.751</td>\n",
       "      <td>27.174</td>\n",
       "      <td>329.561</td>\n",
       "      <td>367.307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[4]</th>\n",
       "      <td>405.960</td>\n",
       "      <td>34.197</td>\n",
       "      <td>378.053</td>\n",
       "      <td>433.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 0]</th>\n",
       "      <td>0.079</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 1]</th>\n",
       "      <td>0.126</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 2]</th>\n",
       "      <td>0.179</td>\n",
       "      <td>0.157</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 3]</th>\n",
       "      <td>0.269</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 4]</th>\n",
       "      <td>0.365</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean         sd  hdi_2.5%  hdi_97.5%\n",
       "a                        -4.861      1.447    -7.748     -2.315\n",
       "alpha                   111.743     37.921    81.477    139.499\n",
       "beta                      8.173      1.543     6.797      9.617\n",
       "log_sigma                 1.857      0.708     0.776      3.238\n",
       "likelihood_missing[0]   408.372     52.684   367.884    440.877\n",
       "sigma2                 1261.074  31508.011     3.312    569.541\n",
       "tau                       0.046      0.045     0.000      0.133\n",
       "mu[0]                   177.124     29.071   155.395    193.343\n",
       "mu[1]                   234.333     24.006   220.789    244.858\n",
       "mu[2]                   291.542     23.254   279.611    304.347\n",
       "mu[3]                   348.751     27.174   329.561    367.307\n",
       "mu[4]                   405.960     34.197   378.053    433.150\n",
       "p[0, 0]                   0.079      0.087     0.000      0.259\n",
       "p[0, 1]                   0.126      0.123     0.000      0.386\n",
       "p[0, 2]                   0.179      0.157     0.000      0.506\n",
       "p[0, 3]                   0.269      0.201     0.000      0.662\n",
       "p[0, 4]                   0.365      0.233     0.000      0.775"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace_3, hdi_prob=0.95, kind=\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee233ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Sun Jul 31 2022\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.10.5\n",
      "IPython version      : 8.4.0\n",
      "\n",
      "aesara: 2.7.7\n",
      "aeppl : 0.0.32\n",
      "\n",
      "pymc : 4.1.3\n",
      "numpy: 1.23.1\n",
      "arviz: 0.12.1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark -n -u -v -iv -p aesara,aeppl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66049290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
