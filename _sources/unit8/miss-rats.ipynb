{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53f3affe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n",
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from pymc.math import dot, stack, concatenate, exp, invlogit, logit\n",
    "\n",
    "%load_ext lab_black\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c66a8a",
   "metadata": {},
   "source": [
    "# Rats\n",
    "\n",
    "This example goes further into dealing with missing data in PyMC, including in the predictor variables.\n",
    "\n",
    "Adapted from [unit 8: ratsignorable1.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsignorable1.odc), [ratsignorable2.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsignorable2.odc), and [ratsinformative.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsinformative.odc).\n",
    "\n",
    "Data can be found [here](https://raw.githubusercontent.com/areding/6420-pymc/main/data/rats.txt).\n",
    "\n",
    "## Associated lecture videos: Unit 8 Lesson 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "531b2796",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed?v=xomK4tcePmc&list=PLv0FeK5oXK4l-RdT6DWJj0_upJOG2WKNO&index=83\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed?v=xomK4tcePmc&list=PLv0FeK5oXK4l-RdT6DWJj0_upJOG2WKNO&index=83\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b1481f",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "We had a previous example about [Dugongs](https://areding.github.io/6420-pymc/Unit6-dugongs.html) that dealt with missing data in the observed data (y values). This example shows how to deal with missing data in the input data (x). It's still pretty easy. You could look at it like creating another likelihood in the model, a very simple one where the observed data is x, and you use a single distribution to fill in the missing values (see ```x_imputed``` in the model below).\n",
    "\n",
    "Original paper [here.](https://www.jstor.org/stable/pdf/2289594.pdf)\n",
    "\n",
    "Gelfand et al 1990 consider the problem of missing data, and delete the last observation of cases 6-10, the last two from 11-20, the last 3 from 21-25 and the last 4 from 26-30.  The appropriate data file is obtained by simply replacing data values by NA (see below). The model specification is unchanged, since the distinction between observed and unobserved quantities is made in the data file and not the model specification. - bugs problem statement\n",
    "\n",
    "This first example only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05ef5ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjusting the shape of x for vectorized calculations (the BUGS example is written as a loop)\n",
    "x = np.array([8.0, 15.0, 22.0, 29.0, 36.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcb46386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import y data and create mask (missing data is represented as nan in the file)\n",
    "y = np.loadtxt(\"../data/rats.txt\")\n",
    "y = np.nan_to_num(y, nan=-1)  # nan to -1\n",
    "y = np.ma.masked_values(y, value=-1)  # create mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a50c22d",
   "metadata": {},
   "source": [
    "original model shapes:\n",
    "\n",
    "shapes of 1:\n",
    "tau_c\n",
    "alpha_c\n",
    "alpha_tau\n",
    "beta_c\n",
    "beta_tau\n",
    "\n",
    "shapes of 30:\n",
    "alpha\n",
    "beta\n",
    "\n",
    "shapes of 30, 5:\n",
    "mu\n",
    "likelihood\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09f5b6f",
   "metadata": {},
   "source": [
    "make a note here about broadcasting, it's the only reason this works.\n",
    "\n",
    "https://numpy.org/doc/stable/user/basics.broadcasting.html\n",
    "\n",
    "another note: pymc doesn't seem to like gamma(.001, .001) for tau here, maybe values getting too close to 0? getting tau > 0 warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "47d345a0",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_c, alpha_tau, beta_c, beta_tau, alpha, beta, lik_tau, likelihood_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='24000' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24000/24000 01:14<00:00 Sampling 4 chains, 23 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 84 seconds.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 11 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 9 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The number of effective samples is smaller than 25% for some parameters.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='20000' class='' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [20000/20000 00:01<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    alpha_c = pm.Normal(\"alpha_c\", 0, tau=1e-6)\n",
    "    alpha_tau = pm.Gamma(\"alpha_tau\", 0.01, 0.01)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, tau=1e-6)\n",
    "    beta_tau = pm.Gamma(\"beta_tau\", 0.01, 0.01)\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", alpha_c, tau=alpha_tau, shape=(30, 1)) # (30, 1) for broadcasting\n",
    "    beta = pm.Normal(\"beta\", beta_c, tau=beta_tau, shape=(30, 1))\n",
    "    lik_tau = pm.Gamma(\"lik_tau\", 0.01, 0.01)\n",
    "    sigma = pm.Deterministic(\"sigma\", 1 / lik_tau**0.5)\n",
    "\n",
    "    mu = alpha + beta * x\n",
    "\n",
    "    pm.Normal(\"likelihood\", mu, tau=lik_tau, observed=y)\n",
    "\n",
    "    trace = pm.sample(\n",
    "        5000,\n",
    "        tune=1000,\n",
    "        cores=4,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0f22aa1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_c</th>\n",
       "      <td>101.223</td>\n",
       "      <td>2.297</td>\n",
       "      <td>96.640</td>\n",
       "      <td>105.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_tau</th>\n",
       "      <td>0.025</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_c</th>\n",
       "      <td>6.567</td>\n",
       "      <td>0.164</td>\n",
       "      <td>6.238</td>\n",
       "      <td>6.884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_tau</th>\n",
       "      <td>2.865</td>\n",
       "      <td>1.208</td>\n",
       "      <td>0.953</td>\n",
       "      <td>5.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>6.009</td>\n",
       "      <td>0.652</td>\n",
       "      <td>4.768</td>\n",
       "      <td>7.307</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean     sd  hdi_2.5%  hdi_97.5%\n",
       "alpha_c    101.223  2.297    96.640    105.714\n",
       "alpha_tau    0.025  0.074     0.004      0.049\n",
       "beta_c       6.567  0.164     6.238      6.884\n",
       "beta_tau     2.865  1.208     0.953      5.181\n",
       "sigma        6.009  0.652     4.768      7.307"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(\n",
    "    trace,\n",
    "    hdi_prob=0.95,\n",
    "    var_names=[\"alpha_c\", \"alpha_tau\", \"beta_c\", \"beta_tau\", \"sigma\"],\n",
    "    kind=\"stats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5008ed",
   "metadata": {
    "tags": [
     "hide_cell"
    ]
   },
   "source": [
    "Notes:\n",
    "\n",
    "- can't impute data with pm.Data(mutable=True)? \n",
    "\n",
    "    - reading: https://github.com/pymc-devs/pymc/issues/4441 https://github.com/pymc-devs/pymc/pull/5295\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d872f3ed",
   "metadata": {},
   "source": [
    "## Model 2: Imputing missing x data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ce60ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the second example, the x data also has a missing value.\n",
    "x = np.array([8.0, 15.0, 22.0, -1, 36.0])\n",
    "x = np.ma.masked_values(x, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bab4c91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[8.0, 15.0, 22.0, --, 36.0],\n",
       "             mask=[False, False, False,  True, False],\n",
       "       fill_value=-1.0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6377817e",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/pymc/model.py:1299: ImputationWarning: Data in x_imputed contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/pymc/model.py:1299: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/pymc/model.py:984: FutureWarning: `Model.initial_point` has been deprecated. Use `Model.recompute_initial_point(seed=None)`.\n",
      "  warnings.warn(\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_c, alpha_tau, beta_c, beta_tau, alpha, beta, lik_tau, x_imputed_missing, likelihood_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='24000' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24000/24000 01:22<00:00 Sampling 4 chains, 23 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 90 seconds.\n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 14 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There was 1 divergence after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    alpha_c = pm.Normal(\"alpha_c\", 0, tau=1e-6)\n",
    "    alpha_tau = pm.Gamma(\"alpha_tau\", 0.01, 0.01)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, tau=1e-6)\n",
    "    beta_tau = pm.Gamma(\"beta_tau\", 0.01, 0.01)\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", alpha_c, tau=alpha_tau, shape=(30, 1))\n",
    "    beta = pm.Normal(\"beta\", beta_c, tau=beta_tau, shape=(30, 1))\n",
    "    lik_tau = pm.Gamma(\"lik_tau\", 0.01, 0.01)\n",
    "    sigma = pm.Deterministic(\"sigma\", 1 / lik_tau**0.5)\n",
    "\n",
    "    x_imputed = pm.TruncatedNormal(\"x_imputed\", mu=20, sigma=10, lower=0, observed=x)\n",
    "\n",
    "    mu = alpha + beta * x_imputed\n",
    "\n",
    "    pm.Normal(\"likelihood\", mu, tau=lik_tau, observed=y)\n",
    "\n",
    "    trace = pm.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "86f47807",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_c</th>\n",
       "      <td>101.872</td>\n",
       "      <td>2.366</td>\n",
       "      <td>97.278</td>\n",
       "      <td>106.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_tau</th>\n",
       "      <td>0.022</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_c</th>\n",
       "      <td>6.507</td>\n",
       "      <td>0.169</td>\n",
       "      <td>6.187</td>\n",
       "      <td>6.853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_tau</th>\n",
       "      <td>3.023</td>\n",
       "      <td>1.293</td>\n",
       "      <td>1.054</td>\n",
       "      <td>5.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>5.974</td>\n",
       "      <td>0.657</td>\n",
       "      <td>4.799</td>\n",
       "      <td>7.356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_imputed_missing[0]</th>\n",
       "      <td>29.502</td>\n",
       "      <td>0.389</td>\n",
       "      <td>28.751</td>\n",
       "      <td>30.274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean     sd  hdi_2.5%  hdi_97.5%\n",
       "alpha_c               101.872  2.366    97.278    106.499\n",
       "alpha_tau               0.022  0.057     0.004      0.042\n",
       "beta_c                  6.507  0.169     6.187      6.853\n",
       "beta_tau                3.023  1.293     1.054      5.600\n",
       "sigma                   5.974  0.657     4.799      7.356\n",
       "x_imputed_missing[0]   29.502  0.389    28.751     30.274"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(\n",
    "    trace,\n",
    "    hdi_prob=0.95,\n",
    "    var_names=[\n",
    "        \"alpha_c\",\n",
    "        \"alpha_tau\",\n",
    "        \"beta_c\",\n",
    "        \"beta_tau\",\n",
    "        \"sigma\",\n",
    "        \"x_imputed_missing\",\n",
    "    ],\n",
    "    kind=\"stats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6967e7",
   "metadata": {},
   "source": [
    "## Model 3: Non-ignorable missingness\n",
    "\n",
    "Probability of missingness increases approx. at a rate of 1% with increasing the weight.\n",
    "\n",
    "Not too sure about this one yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3d95a945",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([177.0, 236.0, 285.0, 350.0, -1])  # original value was 320\n",
    "y = np.ma.masked_values(y, value=-1)  # create masked array\n",
    "# note: can access mask with y.mask, equivalent to the \"miss\" array from the Professor's example\n",
    "miss = y.mask\n",
    "x = np.array([8.0, 15.0, 22.0, 29.0, 36.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9799503e",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/pymc/model.py:1365: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Auto-assigning NUTS sampler...\n",
      "INFO:pymc:Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "INFO:pymc:Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "INFO:pymc:Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, alpha, beta, log_sigma, likelihood_missing]\n",
      "INFO:pymc:NUTS: [a, alpha, beta, log_sigma, likelihood_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='44000' class='' max='44000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [44000/44000 00:19<00:00 Sampling 4 chains, 9,244 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc_env/lib/python3.10/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 1_000 tune and 10_000 draw iterations (4_000 + 40_000 draws total) took 27 seconds.\n",
      "INFO:pymc:Sampling 4 chains for 1_000 tune and 10_000 draw iterations (4_000 + 40_000 draws total) took 27 seconds.\n",
      "There were 783 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 783 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "There were 2908 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 2908 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.4936, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "WARNING:pymc:The acceptance probability does not match the target. It is 0.4936, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 4446 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 4446 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.2868, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "WARNING:pymc:The acceptance probability does not match the target. It is 0.2868, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 1107 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "ERROR:pymc:There were 1107 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.7078, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "WARNING:pymc:The acceptance probability does not match the target. It is 0.7078, but should be close to 0.8. Try to increase the number of tuning steps.\n"
     ]
    }
   ],
   "source": [
    "t = 0.1\n",
    "s = 1 / t**2\n",
    "b = np.log(1.01)\n",
    "\n",
    "with pm.Model() as m:\n",
    "    a = pm.Logistic(\"a\", mu=0, s=s)\n",
    "    alpha = pm.Flat(\"alpha\")\n",
    "    beta = pm.Flat(\"beta\")\n",
    "    log_sigma = pm.Flat(\"log_sigma\")\n",
    "    sigma2 = pm.Deterministic(\"sigma2\", exp(2 * log_sigma))\n",
    "    tau = pm.Deterministic(\"tau\", 1 / sigma2)\n",
    "\n",
    "    p = pm.Deterministic(\"p\", invlogit(a + b * y))\n",
    "    missing = pm.Bernoulli(\"missing\", p=p, observed=miss)\n",
    "\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta * x)\n",
    "\n",
    "    pm.Normal(\"likelihood\", mu, tau=tau, observed=y)\n",
    "\n",
    "    trace = pm.sample(10000, tune=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "63118b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-4.265</td>\n",
       "      <td>1.428</td>\n",
       "      <td>-7.510</td>\n",
       "      <td>-1.594</td>\n",
       "      <td>0.100</td>\n",
       "      <td>0.082</td>\n",
       "      <td>330.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>111.793</td>\n",
       "      <td>17.251</td>\n",
       "      <td>86.087</td>\n",
       "      <td>137.615</td>\n",
       "      <td>0.212</td>\n",
       "      <td>0.160</td>\n",
       "      <td>3238.0</td>\n",
       "      <td>3663.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>8.120</td>\n",
       "      <td>0.859</td>\n",
       "      <td>6.865</td>\n",
       "      <td>9.449</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.008</td>\n",
       "      <td>2907.0</td>\n",
       "      <td>3555.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_sigma</th>\n",
       "      <td>1.833</td>\n",
       "      <td>0.628</td>\n",
       "      <td>0.780</td>\n",
       "      <td>3.051</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.020</td>\n",
       "      <td>334.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood_missing[0]</th>\n",
       "      <td>404.160</td>\n",
       "      <td>20.319</td>\n",
       "      <td>374.390</td>\n",
       "      <td>438.782</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.193</td>\n",
       "      <td>2991.0</td>\n",
       "      <td>4203.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma2</th>\n",
       "      <td>175.791</td>\n",
       "      <td>1772.611</td>\n",
       "      <td>2.904</td>\n",
       "      <td>428.624</td>\n",
       "      <td>23.592</td>\n",
       "      <td>16.683</td>\n",
       "      <td>334.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.041</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>334.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>1.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0]</th>\n",
       "      <td>0.125</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.374</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "      <td>330.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[1]</th>\n",
       "      <td>0.191</td>\n",
       "      <td>0.160</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.004</td>\n",
       "      <td>330.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[2]</th>\n",
       "      <td>0.261</td>\n",
       "      <td>0.192</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.636</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.005</td>\n",
       "      <td>330.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[3]</th>\n",
       "      <td>0.371</td>\n",
       "      <td>0.228</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.007</td>\n",
       "      <td>330.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[4]</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>330.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[0]</th>\n",
       "      <td>176.750</td>\n",
       "      <td>11.131</td>\n",
       "      <td>160.280</td>\n",
       "      <td>194.131</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.099</td>\n",
       "      <td>3787.0</td>\n",
       "      <td>4112.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[1]</th>\n",
       "      <td>233.587</td>\n",
       "      <td>7.033</td>\n",
       "      <td>222.741</td>\n",
       "      <td>244.500</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.046</td>\n",
       "      <td>6195.0</td>\n",
       "      <td>5221.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[2]</th>\n",
       "      <td>290.424</td>\n",
       "      <td>6.887</td>\n",
       "      <td>279.295</td>\n",
       "      <td>301.511</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.046</td>\n",
       "      <td>4652.0</td>\n",
       "      <td>5219.0</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[3]</th>\n",
       "      <td>347.262</td>\n",
       "      <td>10.854</td>\n",
       "      <td>329.820</td>\n",
       "      <td>363.651</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.096</td>\n",
       "      <td>3619.0</td>\n",
       "      <td>4624.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[4]</th>\n",
       "      <td>404.099</td>\n",
       "      <td>16.142</td>\n",
       "      <td>379.825</td>\n",
       "      <td>429.415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.153</td>\n",
       "      <td>3175.0</td>\n",
       "      <td>4158.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean        sd  hdi_2.5%  hdi_97.5%  mcse_mean  \\\n",
       "a                       -4.265     1.428    -7.510     -1.594      0.100   \n",
       "alpha                  111.793    17.251    86.087    137.615      0.212   \n",
       "beta                     8.120     0.859     6.865      9.449      0.012   \n",
       "log_sigma                1.833     0.628     0.780      3.051      0.029   \n",
       "likelihood_missing[0]  404.160    20.319   374.390    438.782      0.264   \n",
       "sigma2                 175.791  1772.611     2.904    428.624     23.592   \n",
       "tau                      0.044     0.041     0.000      0.132      0.003   \n",
       "p[0]                     0.125     0.120     0.000      0.374      0.004   \n",
       "p[1]                     0.191     0.160     0.000      0.518      0.006   \n",
       "p[2]                     0.261     0.192     0.000      0.636      0.007   \n",
       "p[3]                     0.371     0.228     0.002      0.771      0.010   \n",
       "p[4]                     0.028     0.036     0.000      0.092      0.001   \n",
       "mu[0]                  176.750    11.131   160.280    194.131      0.121   \n",
       "mu[1]                  233.587     7.033   222.741    244.500      0.059   \n",
       "mu[2]                  290.424     6.887   279.295    301.511      0.062   \n",
       "mu[3]                  347.262    10.854   329.820    363.651      0.132   \n",
       "mu[4]                  404.099    16.142   379.825    429.415      0.210   \n",
       "\n",
       "                       mcse_sd  ess_bulk  ess_tail  r_hat  \n",
       "a                        0.082     330.0     118.0   1.01  \n",
       "alpha                    0.160    3238.0    3663.0   1.00  \n",
       "beta                     0.008    2907.0    3555.0   1.00  \n",
       "log_sigma                0.020     334.0     246.0   1.03  \n",
       "likelihood_missing[0]    0.193    2991.0    4203.0   1.00  \n",
       "sigma2                  16.683     334.0     246.0   1.03  \n",
       "tau                      0.002     334.0     245.0   1.03  \n",
       "p[0]                     0.003     330.0     118.0   1.01  \n",
       "p[1]                     0.004     330.0     118.0   1.01  \n",
       "p[2]                     0.005     330.0     118.0   1.01  \n",
       "p[3]                     0.007     330.0     118.0   1.01  \n",
       "p[4]                     0.001     330.0     118.0   1.01  \n",
       "mu[0]                    0.099    3787.0    4112.0   1.01  \n",
       "mu[1]                    0.046    6195.0    5221.0   1.00  \n",
       "mu[2]                    0.046    4652.0    5219.0   1.01  \n",
       "mu[3]                    0.096    3619.0    4624.0   1.00  \n",
       "mu[4]                    0.153    3175.0    4158.0   1.00  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77f00e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.4\n",
      "IPython version      : 8.4.0\n",
      "\n",
      "pymc : 4.0.0\n",
      "arviz: 0.12.1\n",
      "numpy: 1.22.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022f70b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
