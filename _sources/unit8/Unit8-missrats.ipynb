{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a63309b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from pymc.math import dot, stack, concatenate, exp, invlogit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa33d9",
   "metadata": {},
   "source": [
    "# 2. Rats Example with Missing Data*\n",
    "\n",
    "This example goes further into dealing with missing data in PyMC, including in the predictor variables.\n",
    "\n",
    "Adapted from [Unit 8: ratsignorable1.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsignorable1.odc), [ratsignorable2.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsignorable2.odc), and [ratsinformative.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit8/ratsinformative.odc).\n",
    "\n",
    "Data can be found [here](https://raw.githubusercontent.com/areding/6420-pymc/main/data/rats.txt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a80d0a",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "We had a previous example about [dugongs](https://areding.github.io/6420-pymc/unit6/Unit6-missingdata.html) that dealt with missing data in the observed data (y values). This example shows how to deal with missing data in the input data (x). It's still pretty easy. You could look at it like creating another likelihood in the model, a very simple one where the observed data is x, and you use a single distribution to fill in the missing values (see ```x_imputed``` in the model below).\n",
    "\n",
    "Original paper [here.](https://www.jstor.org/stable/pdf/2289594.pdf)\n",
    "\n",
    "Gelfand et al 1990 consider the problem of missing data, and delete the last observation of cases 6-10, the last two from 11-20, the last 3 from 21-25 and the last 4 from 26-30.  The appropriate data file is obtained by simply replacing data values by NA (see below). The model specification is unchanged, since the distinction between observed and unobserved quantities is made in the data file and not the model specification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bff621e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([8.0, 15.0, 22.0, 29.0, 36.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91d405a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151., 199., 246., 283., 320.],\n",
       "       [145., 199., 249., 293., 354.],\n",
       "       [147., 214., 263., 312., 328.],\n",
       "       [155., 200., 237., 272., 297.],\n",
       "       [135., 188., 230., 280., 323.],\n",
       "       [159., 210., 252., 298.,  nan],\n",
       "       [141., 189., 231., 275.,  nan],\n",
       "       [159., 201., 248., 297.,  nan],\n",
       "       [177., 236., 285., 350.,  nan],\n",
       "       [134., 182., 220., 260.,  nan],\n",
       "       [160., 208., 261., 313.,  nan],\n",
       "       [143., 188., 220.,  nan,  nan],\n",
       "       [154., 200., 244.,  nan,  nan],\n",
       "       [171., 221., 270.,  nan,  nan],\n",
       "       [163., 216., 242.,  nan,  nan],\n",
       "       [160., 207., 248.,  nan,  nan],\n",
       "       [142., 187., 234.,  nan,  nan],\n",
       "       [156., 203., 243.,  nan,  nan],\n",
       "       [157., 212., 259.,  nan,  nan],\n",
       "       [152., 203., 246.,  nan,  nan],\n",
       "       [154., 205., 253.,  nan,  nan],\n",
       "       [139., 190.,  nan,  nan,  nan],\n",
       "       [146., 191.,  nan,  nan,  nan],\n",
       "       [157., 211.,  nan,  nan,  nan],\n",
       "       [132., 185.,  nan,  nan,  nan],\n",
       "       [160.,  nan,  nan,  nan,  nan],\n",
       "       [169.,  nan,  nan,  nan,  nan],\n",
       "       [157.,  nan,  nan,  nan,  nan],\n",
       "       [137.,  nan,  nan,  nan,  nan],\n",
       "       [153.,  nan,  nan,  nan,  nan]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import y data and create mask (missing data is represented as nan in the file)\n",
    "y = np.loadtxt(\"../data/rats.txt\")\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cf67ff-c761-4106-ba98-20d755cf5631",
   "metadata": {},
   "source": [
    "## Model 1\n",
    "\n",
    "This first model we only have missing data in our response variable (y). Notice that I made the shapes of alpha and beta (30, 1) instead of just 30. This is so that they broadcast correctly when combined (```mu = alpha + beta * x```). The NumPy docs have a helpful [page about broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ddac632e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/pymc/model/core.py:1302: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_c, alpha_tau, beta_c, beta_tau, alpha, beta, lik_tau, likelihood_unobserved]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daafa8fdb0184867bcb85ebda1a01c73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 4_000 tune and 5_000 draw iterations (16_000 + 20_000 draws total) took 57 seconds.\n",
      "There were 9 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "prior_tau = 1e-4\n",
    "\n",
    "with pm.Model() as m:\n",
    "    alpha_c = pm.Normal(\"alpha_c\", 0, tau=prior_tau)\n",
    "    alpha_tau = pm.Gamma(\"alpha_tau\", 0.001, 0.001)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, tau=prior_tau)\n",
    "    beta_tau = pm.Gamma(\"beta_tau\", 0.001, 0.001)\n",
    "\n",
    "    alpha = pm.Normal(\n",
    "        \"alpha\", alpha_c, tau=alpha_tau, shape=(30, 1)\n",
    "    )  # (30, 1) for broadcasting\n",
    "    beta = pm.Normal(\"beta\", beta_c, tau=beta_tau, shape=(30, 1))\n",
    "    lik_tau = pm.Gamma(\"lik_tau\", 0.001, 0.001)\n",
    "    sigma = pm.Deterministic(\"sigma\", 1 / lik_tau**0.5)\n",
    "\n",
    "    mu = alpha + beta * x\n",
    "\n",
    "    pm.Normal(\"likelihood\", mu, tau=lik_tau, observed=y)\n",
    "\n",
    "    trace = pm.sample(\n",
    "        5000,\n",
    "        tune=4000,\n",
    "        init=\"jitter+adapt_diag_grad\",\n",
    "        target_accept=0.95,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c215f8bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_c</th>\n",
       "      <td>101.153</td>\n",
       "      <td>2.288</td>\n",
       "      <td>96.525</td>\n",
       "      <td>105.542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_tau</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.104</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_c</th>\n",
       "      <td>6.569</td>\n",
       "      <td>0.164</td>\n",
       "      <td>6.242</td>\n",
       "      <td>6.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_tau</th>\n",
       "      <td>2.851</td>\n",
       "      <td>1.212</td>\n",
       "      <td>0.927</td>\n",
       "      <td>5.181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>6.024</td>\n",
       "      <td>0.655</td>\n",
       "      <td>4.816</td>\n",
       "      <td>7.330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean     sd  hdi_2.5%  hdi_97.5%\n",
       "alpha_c    101.153  2.288    96.525    105.542\n",
       "alpha_tau    0.028  0.104     0.004      0.050\n",
       "beta_c       6.569  0.164     6.242      6.891\n",
       "beta_tau     2.851  1.212     0.927      5.181\n",
       "sigma        6.024  0.655     4.816      7.330"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(\n",
    "    trace,\n",
    "    hdi_prob=0.95,\n",
    "    var_names=[\"alpha_c\", \"alpha_tau\", \"beta_c\", \"beta_tau\", \"sigma\"],\n",
    "    kind=\"stats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5beaab3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Model 2: Imputing missing predictor variable data\n",
    "\n",
    "This is the same model, except we now have missing x data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc7494b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_miss = np.array([8.0, 15.0, 22.0, np.nan, 36.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f00743b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8., 15., 22., nan, 36.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c4be27a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/pymc/model/core.py:1302: ImputationWarning: Data in x_imputed contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/pymc/model/core.py:1302: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Initializing NUTS using jitter+adapt_diag_grad...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha_c, alpha_tau, beta_c, beta_tau, alpha, beta, lik_tau, x_imputed_unobserved, likelihood_unobserved]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b66819bed754f2ea1ae41593736de96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 4_000 tune and 5_000 draw iterations (16_000 + 20_000 draws total) took 44 seconds.\n",
      "There were 6 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "prior_tau = 1e-4\n",
    "\n",
    "with pm.Model() as m:\n",
    "    alpha_c = pm.Normal(\"alpha_c\", 0, tau=prior_tau)\n",
    "    alpha_tau = pm.Gamma(\"alpha_tau\", 0.001, 0.001)\n",
    "    beta_c = pm.Normal(\"beta_c\", 0, tau=prior_tau)\n",
    "    beta_tau = pm.Gamma(\"beta_tau\", 0.001, 0.001)\n",
    "\n",
    "    alpha = pm.Normal(\"alpha\", alpha_c, tau=alpha_tau, shape=(30, 1))\n",
    "    beta = pm.Normal(\"beta\", beta_c, tau=beta_tau, shape=(30, 1))\n",
    "    lik_tau = pm.Gamma(\"lik_tau\", 0.001, 0.001)\n",
    "    sigma = pm.Deterministic(\"sigma\", 1 / lik_tau**0.5)\n",
    "\n",
    "    x_imputed = pm.Normal(\"x_imputed\", mu=20, sigma=5, observed=x_miss)\n",
    "\n",
    "    mu = alpha + beta * x_imputed\n",
    "\n",
    "    pm.Normal(\"likelihood\", mu, tau=lik_tau, observed=y)\n",
    "\n",
    "    trace_2 = pm.sample(\n",
    "        5000, tune=4000, init=\"jitter+adapt_diag_grad\", target_accept=0.87\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928b4518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/arviz/stats/diagnostics.py:596: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/arviz/stats/diagnostics.py:991: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  varsd = varvar / evar / 4\n",
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/arviz/stats/diagnostics.py:596: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  (between_chain_variance / within_chain_variance + num_samples - 1) / (num_samples)\n",
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/arviz/stats/diagnostics.py:991: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  varsd = varvar / evar / 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x_imputed[0]</th>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_imputed[1]</th>\n",
       "      <td>15.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>15.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_imputed[2]</th>\n",
       "      <td>22.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>22.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_imputed[3]</th>\n",
       "      <td>29.455</td>\n",
       "      <td>0.387</td>\n",
       "      <td>28.682</td>\n",
       "      <td>30.207</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.003</td>\n",
       "      <td>25583.0</td>\n",
       "      <td>16308.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x_imputed[4]</th>\n",
       "      <td>36.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>36.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                mean     sd  hdi_2.5%  hdi_97.5%  mcse_mean  mcse_sd  \\\n",
       "x_imputed[0]   8.000  0.000     8.000      8.000      0.000      NaN   \n",
       "x_imputed[1]  15.000  0.000    15.000     15.000      0.000      NaN   \n",
       "x_imputed[2]  22.000  0.000    22.000     22.000      0.000      NaN   \n",
       "x_imputed[3]  29.455  0.387    28.682     30.207      0.002    0.003   \n",
       "x_imputed[4]  36.000  0.000    36.000     36.000      0.000      NaN   \n",
       "\n",
       "              ess_bulk  ess_tail  r_hat  \n",
       "x_imputed[0]   20000.0   20000.0    NaN  \n",
       "x_imputed[1]   20000.0   20000.0    NaN  \n",
       "x_imputed[2]   20000.0   20000.0    NaN  \n",
       "x_imputed[3]   25583.0   16308.0    1.0  \n",
       "x_imputed[4]   20000.0   20000.0    NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace_2, hdi_prob=0.95, var_names=[\"x_imputed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09bed4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alpha_c</th>\n",
       "      <td>101.715</td>\n",
       "      <td>2.353</td>\n",
       "      <td>97.130</td>\n",
       "      <td>106.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_c</th>\n",
       "      <td>6.516</td>\n",
       "      <td>0.168</td>\n",
       "      <td>6.181</td>\n",
       "      <td>6.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha_tau</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_tau</th>\n",
       "      <td>2.981</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.996</td>\n",
       "      <td>5.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lik_tau</th>\n",
       "      <td>0.029</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              mean     sd  hdi_2.5%  hdi_97.5%\n",
       "alpha_c    101.715  2.353    97.130    106.496\n",
       "beta_c       6.516  0.168     6.181      6.838\n",
       "alpha_tau    0.021  0.051     0.004      0.042\n",
       "beta_tau     2.981  1.273     0.996      5.448\n",
       "lik_tau      0.029  0.006     0.017      0.041"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(\n",
    "    trace_2,\n",
    "    hdi_prob=0.95,\n",
    "    var_names=[\"alpha_c\", \"beta_c\", \"alpha_tau\", \"beta_tau\", \"lik_tau\"],\n",
    "    kind=\"stats\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b679604",
   "metadata": {},
   "source": [
    "## Model 3: Non-ignorable missingness\n",
    "\n",
    "Odds of missingness increases approx. at a rate of 1% with increasing the weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06e3cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.atleast_2d(\n",
    "    np.array([177.0, 236.0, 285.0, 350.0, -1])\n",
    ")  # original value was 320\n",
    "y = np.ma.masked_values(y, value=-1)  # create masked array\n",
    "# y.mask is equivalent to the \"miss\" array from the professor's example\n",
    "miss = y.mask\n",
    "x = np.array([8.0, 15.0, 22.0, 29.0, 36.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e747223d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/miniforge3/envs/pymc_f25_2/lib/python3.13/site-packages/pymc/model/core.py:1302: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Initializing NUTS using adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [a, alpha, beta, sigma, likelihood_unobserved]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb77ab1a7bad44fda30540ba372fec36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 4_000 tune and 5_000 draw iterations (16_000 + 20_000 draws total) took 8 seconds.\n"
     ]
    }
   ],
   "source": [
    "t = 0.1\n",
    "s = 1 / t  # convert BUGS dlogis tau to s for pymc\n",
    "b = np.log(1.01)\n",
    "\n",
    "with pm.Model() as m:\n",
    "    a = pm.Logistic(\"a\", mu=0, s=s)\n",
    "    # adjusting alpha, beta, sigma priors to be weakly informative compared\n",
    "    # to old flat priors in order to get rid of divergences.\n",
    "    alpha = pm.Normal(\"alpha\", 0, 10)\n",
    "    beta = pm.Normal(\"beta\", 0, 10)\n",
    "    sigma = pm.Exponential(\"sigma\", 0.01)\n",
    "\n",
    "    mu = pm.Deterministic(\"mu\", alpha + beta * x)\n",
    "    y_imputed = pm.Normal(\"likelihood\", mu, sigma, observed=y)\n",
    "\n",
    "    p = pm.Deterministic(\"p\", invlogit(a + b * y_imputed))\n",
    "    pm.Bernoulli(\"missing\", p=p, observed=miss)\n",
    "\n",
    "    trace_3 = pm.sample(\n",
    "        5000,\n",
    "        tune=4000,\n",
    "        init=\"adapt_diag\",\n",
    "        target_accept=0.95,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4dd4ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 13.1.2 (0)\n",
       " -->\n",
       "<!-- Pages: 1 -->\n",
       "<svg width=\"440pt\" height=\"698pt\"\n",
       " viewBox=\"0.00 0.00 440.00 698.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 693.68)\">\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-693.68 436,-693.68 436,4 -4,4\"/>\n",
       "<g id=\"clust1\" class=\"cluster\">\n",
       "<title>cluster5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M253,-470.45C253,-470.45 335,-470.45 335,-470.45 341,-470.45 347,-476.45 347,-482.45 347,-482.45 347,-556.45 347,-556.45 347,-562.45 341,-568.45 335,-568.45 335,-568.45 253,-568.45 253,-568.45 247,-568.45 241,-562.45 241,-556.45 241,-556.45 241,-482.45 241,-482.45 241,-476.45 247,-470.45 253,-470.45\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"335.62\" y=\"-477.65\" font-family=\"Times,serif\" font-size=\"14.00\">5</text>\n",
       "</g>\n",
       "<g id=\"clust2\" class=\"cluster\">\n",
       "<title>cluster4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M20,-340.63C20,-340.63 190,-340.63 190,-340.63 196,-340.63 202,-346.63 202,-352.63 202,-352.63 202,-450.45 202,-450.45 202,-456.45 196,-462.45 190,-462.45 190,-462.45 20,-462.45 20,-462.45 14,-462.45 8,-456.45 8,-450.45 8,-450.45 8,-352.63 8,-352.63 8,-346.63 14,-340.63 20,-340.63\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"190.62\" y=\"-347.83\" font-family=\"Times,serif\" font-size=\"14.00\">4</text>\n",
       "</g>\n",
       "<g id=\"clust3\" class=\"cluster\">\n",
       "<title>cluster1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222,-340.63C222,-340.63 412,-340.63 412,-340.63 418,-340.63 424,-346.63 424,-352.63 424,-352.63 424,-450.45 424,-450.45 424,-456.45 418,-462.45 412,-462.45 412,-462.45 222,-462.45 222,-462.45 216,-462.45 210,-456.45 210,-450.45 210,-450.45 210,-352.63 210,-352.63 210,-346.63 216,-340.63 222,-340.63\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"412.62\" y=\"-347.83\" font-family=\"Times,serif\" font-size=\"14.00\">1</text>\n",
       "</g>\n",
       "<g id=\"clust4\" class=\"cluster\">\n",
       "<title>cluster1 x 5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M168,-8C168,-8 254,-8 254,-8 260,-8 266,-14 266,-20 266,-20 266,-316.73 266,-316.73 266,-322.73 260,-328.73 254,-328.73 254,-328.73 168,-328.73 168,-328.73 162,-328.73 156,-322.73 156,-316.73 156,-316.73 156,-20 156,-20 156,-14 162,-8 168,-8\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"244.12\" y=\"-15.2\" font-family=\"Times,serif\" font-size=\"14.00\">1 x 5</text>\n",
       "</g>\n",
       "<!-- sigma -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>sigma</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"128\" cy=\"-531.7\" rx=\"57.45\" ry=\"40.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"128\" y=\"-543.15\" font-family=\"Times,serif\" font-size=\"14.00\">sigma</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"128\" y=\"-526.65\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"128\" y=\"-510.15\" font-family=\"Times,serif\" font-size=\"14.00\">Exponential</text>\n",
       "</g>\n",
       "<!-- likelihood_observed -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>likelihood_observed</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"105\" cy=\"-413.79\" rx=\"89.27\" ry=\"40.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"105\" y=\"-425.24\" font-family=\"Times,serif\" font-size=\"14.00\">likelihood_observed</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"105\" y=\"-408.74\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"105\" y=\"-392.24\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;likelihood_observed -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;likelihood_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M120.15,-491.14C118.52,-482.93 116.78,-474.17 115.09,-465.62\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"118.57,-465.19 113.19,-456.06 111.7,-466.55 118.57,-465.19\"/>\n",
       "</g>\n",
       "<!-- likelihood_unobserved -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>likelihood_unobserved</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"317\" cy=\"-413.79\" rx=\"98.82\" ry=\"40.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"317\" y=\"-425.24\" font-family=\"Times,serif\" font-size=\"14.00\">likelihood_unobserved</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"317\" y=\"-408.74\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"317\" y=\"-392.24\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- sigma&#45;&gt;likelihood_unobserved -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>sigma&#45;&gt;likelihood_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.89,-504.4C195.14,-489.53 225.93,-470.65 252.98,-454.05\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"254.78,-457.06 261.47,-448.85 251.12,-451.09 254.78,-457.06\"/>\n",
       "</g>\n",
       "<!-- beta -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>beta</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"244\" cy=\"-649.02\" rx=\"41.01\" ry=\"40.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"244\" y=\"-660.47\" font-family=\"Times,serif\" font-size=\"14.00\">beta</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"244\" y=\"-643.97\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"244\" y=\"-627.47\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- mu -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>mu</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"339.12,-560.45 248.88,-560.45 248.88,-502.95 339.12,-502.95 339.12,-560.45\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"294\" y=\"-543.15\" font-family=\"Times,serif\" font-size=\"14.00\">mu</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"294\" y=\"-526.65\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"294\" y=\"-510.15\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- beta&#45;&gt;mu -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>beta&#45;&gt;mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M259.96,-611.21C265.5,-598.44 271.72,-584.1 277.31,-571.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"280.47,-572.72 281.23,-562.15 274.04,-569.93 280.47,-572.72\"/>\n",
       "</g>\n",
       "<!-- a -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"317\" cy=\"-291.98\" rx=\"42.6\" ry=\"40.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"317\" y=\"-303.43\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"317\" y=\"-286.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"317\" y=\"-270.43\" font-family=\"Times,serif\" font-size=\"14.00\">Logistic</text>\n",
       "</g>\n",
       "<!-- p -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>p</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"256.12,-215.32 165.88,-215.32 165.88,-157.82 256.12,-157.82 256.12,-215.32\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-198.02\" font-family=\"Times,serif\" font-size=\"14.00\">p</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-181.52\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-165.02\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- a&#45;&gt;p -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>a&#45;&gt;p</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M287.47,-262.17C275.09,-250.1 260.58,-235.93 247.53,-223.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"250.32,-221.04 240.72,-216.56 245.43,-226.05 250.32,-221.04\"/>\n",
       "</g>\n",
       "<!-- alpha -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>alpha</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"344\" cy=\"-649.02\" rx=\"41.01\" ry=\"40.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"344\" y=\"-660.47\" font-family=\"Times,serif\" font-size=\"14.00\">alpha</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"344\" y=\"-643.97\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"344\" y=\"-627.47\" font-family=\"Times,serif\" font-size=\"14.00\">Normal</text>\n",
       "</g>\n",
       "<!-- alpha&#45;&gt;mu -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>alpha&#45;&gt;mu</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M328.04,-611.21C322.5,-598.44 316.28,-584.1 310.69,-571.19\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"313.96,-569.93 306.77,-562.15 307.53,-572.72 313.96,-569.93\"/>\n",
       "</g>\n",
       "<!-- mu&#45;&gt;likelihood_observed -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>mu&#45;&gt;likelihood_observed</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.73,-502.94C224.32,-487.97 193.82,-469.27 167.21,-452.95\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"169.25,-450.09 158.89,-447.84 165.59,-456.05 169.25,-450.09\"/>\n",
       "</g>\n",
       "<!-- mu&#45;&gt;likelihood_unobserved -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>mu&#45;&gt;likelihood_unobserved</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M299.57,-502.64C301.79,-491.45 304.42,-478.21 306.95,-465.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"310.33,-466.39 308.84,-455.9 303.46,-465.03 310.33,-466.39\"/>\n",
       "</g>\n",
       "<!-- likelihood -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>likelihood</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"256.12,-320.73 165.88,-320.73 165.88,-263.23 256.12,-263.23 256.12,-320.73\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-303.43\" font-family=\"Times,serif\" font-size=\"14.00\">likelihood</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-286.93\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-270.43\" font-family=\"Times,serif\" font-size=\"14.00\">Deterministic</text>\n",
       "</g>\n",
       "<!-- likelihood_observed&#45;&gt;likelihood -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>likelihood_observed&#45;&gt;likelihood</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M137.96,-375.54C150.96,-360.84 165.86,-344 178.79,-329.39\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"181.14,-332.01 185.14,-322.2 175.9,-327.37 181.14,-332.01\"/>\n",
       "</g>\n",
       "<!-- likelihood_unobserved&#45;&gt;likelihood -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>likelihood_unobserved&#45;&gt;likelihood</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M283.75,-375.21C270.76,-360.52 255.92,-343.75 243.04,-329.2\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"245.97,-327.22 236.72,-322.05 240.73,-331.86 245.97,-327.22\"/>\n",
       "</g>\n",
       "<!-- missing -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>missing</title>\n",
       "<ellipse fill=\"lightgrey\" stroke=\"black\" cx=\"211\" cy=\"-81.16\" rx=\"47.38\" ry=\"40.66\"/>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-92.61\" font-family=\"Times,serif\" font-size=\"14.00\">missing</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-76.11\" font-family=\"Times,serif\" font-size=\"14.00\">~</text>\n",
       "<text xml:space=\"preserve\" text-anchor=\"middle\" x=\"211\" y=\"-59.61\" font-family=\"Times,serif\" font-size=\"14.00\">Bernoulli</text>\n",
       "</g>\n",
       "<!-- p&#45;&gt;missing -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>p&#45;&gt;missing</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211,-157.58C211,-150.1 211,-141.77 211,-133.45\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"214.5,-133.71 211,-123.71 207.5,-133.71 214.5,-133.71\"/>\n",
       "</g>\n",
       "<!-- likelihood&#45;&gt;p -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>likelihood&#45;&gt;p</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211,-262.99C211,-251.84 211,-238.81 211,-226.75\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"214.5,-227.09 211,-217.09 207.5,-227.09 214.5,-227.09\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x166c45a90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pm.model_to_graphviz(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3e39419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>-5.204</td>\n",
       "      <td>1.506</td>\n",
       "      <td>-8.263</td>\n",
       "      <td>-2.464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>2.548</td>\n",
       "      <td>10.043</td>\n",
       "      <td>-16.816</td>\n",
       "      <td>22.017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>13.281</td>\n",
       "      <td>1.852</td>\n",
       "      <td>9.658</td>\n",
       "      <td>17.159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood_unobserved[0]</th>\n",
       "      <td>509.814</td>\n",
       "      <td>98.367</td>\n",
       "      <td>328.598</td>\n",
       "      <td>718.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>69.027</td>\n",
       "      <td>37.265</td>\n",
       "      <td>23.474</td>\n",
       "      <td>142.419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[0]</th>\n",
       "      <td>108.797</td>\n",
       "      <td>15.665</td>\n",
       "      <td>76.220</td>\n",
       "      <td>139.202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[1]</th>\n",
       "      <td>201.766</td>\n",
       "      <td>27.059</td>\n",
       "      <td>147.625</td>\n",
       "      <td>257.509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[2]</th>\n",
       "      <td>294.734</td>\n",
       "      <td>39.436</td>\n",
       "      <td>214.536</td>\n",
       "      <td>374.400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[3]</th>\n",
       "      <td>387.703</td>\n",
       "      <td>52.101</td>\n",
       "      <td>284.710</td>\n",
       "      <td>495.874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mu[4]</th>\n",
       "      <td>480.671</td>\n",
       "      <td>64.885</td>\n",
       "      <td>354.731</td>\n",
       "      <td>617.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood[0, 0]</th>\n",
       "      <td>177.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>177.000</td>\n",
       "      <td>177.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood[0, 1]</th>\n",
       "      <td>236.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>236.000</td>\n",
       "      <td>236.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood[0, 2]</th>\n",
       "      <td>285.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>285.000</td>\n",
       "      <td>285.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood[0, 3]</th>\n",
       "      <td>350.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>350.000</td>\n",
       "      <td>350.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood[0, 4]</th>\n",
       "      <td>509.814</td>\n",
       "      <td>98.367</td>\n",
       "      <td>328.598</td>\n",
       "      <td>718.465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 0]</th>\n",
       "      <td>0.063</td>\n",
       "      <td>0.076</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 1]</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 2]</th>\n",
       "      <td>0.146</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 3]</th>\n",
       "      <td>0.225</td>\n",
       "      <td>0.190</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p[0, 4]</th>\n",
       "      <td>0.484</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             mean      sd  hdi_2.5%  hdi_97.5%\n",
       "a                          -5.204   1.506    -8.263     -2.464\n",
       "alpha                       2.548  10.043   -16.816     22.017\n",
       "beta                       13.281   1.852     9.658     17.159\n",
       "likelihood_unobserved[0]  509.814  98.367   328.598    718.465\n",
       "sigma                      69.027  37.265    23.474    142.419\n",
       "mu[0]                     108.797  15.665    76.220    139.202\n",
       "mu[1]                     201.766  27.059   147.625    257.509\n",
       "mu[2]                     294.734  39.436   214.536    374.400\n",
       "mu[3]                     387.703  52.101   284.710    495.874\n",
       "mu[4]                     480.671  64.885   354.731    617.973\n",
       "likelihood[0, 0]          177.000   0.000   177.000    177.000\n",
       "likelihood[0, 1]          236.000   0.000   236.000    236.000\n",
       "likelihood[0, 2]          285.000   0.000   285.000    285.000\n",
       "likelihood[0, 3]          350.000   0.000   350.000    350.000\n",
       "likelihood[0, 4]          509.814  98.367   328.598    718.465\n",
       "p[0, 0]                     0.063   0.076     0.000      0.217\n",
       "p[0, 1]                     0.102   0.110     0.000      0.333\n",
       "p[0, 2]                     0.146   0.144     0.000      0.448\n",
       "p[0, 3]                     0.225   0.190     0.000      0.608\n",
       "p[0, 4]                     0.484   0.271     0.004      0.912"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace_3, hdi_prob=0.95, kind=\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee233ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Wed Dec 03 2025\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.13.8\n",
      "IPython version      : 9.6.0\n",
      "\n",
      "pytensor: 2.28.3\n",
      "\n",
      "pytensor: 2.28.3\n",
      "pymc    : 5.21.1\n",
      "numpy   : 2.3.3\n",
      "arviz   : 0.22.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -p pytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66049290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_f25_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
