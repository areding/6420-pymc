{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "878001b4-b685-4ee1-a826-5fb1e924a218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "arviz: 0.11.4\n",
      "numpy: 1.22.3\n",
      "pymc : 4.0.0b4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "from pymc.math import dot\n",
    "\n",
    "%load_ext watermark\n",
    "%watermark --iversions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808f6b8e-7543-41a7-8c33-693039a17fbb",
   "metadata": {},
   "source": [
    "# Rats \n",
    "\n",
    "I'm just going to do ratsignorable2.odc for now since it is relevant for HW6. Eventually I'll add the other examples.\n",
    "\n",
    "Adapted from [Codes for Unit 8: ratsignorable2.odc](https://www2.isye.gatech.edu/isye6420/supporting.html).\n",
    "\n",
    "Associated lecture video: [Unit 8 Lesson 2](https://www.youtube.com/watch?v=T5vkLsIs3f8&list=PLv0FeK5oXK4l-RdT6DWJj0_upJOG2WKNO&index=83).\n",
    "\n",
    "Data can be found [here](https://raw.githubusercontent.com/areding/6420-pymc/main/data/rats.txt).\n",
    "\n",
    "We had a previous example about [Dugongs](https://areding.github.io/6420-pymc/Unit6-dugongs.html) that dealt with missing data in the observed data (y values). This example shows how to deal with missing data in the input data (x). It's still pretty easy. You could look at it like creating another likelihood in the model, a very simple one where the observed data is x, and you use a single distribution to fill in the missing values (see ```x_imputed``` in the model below).\n",
    "\n",
    "For now I'm leaving the variable names the same as the BUGS example. Might go back and make them more descriptive later.\n",
    "\n",
    "There are some differences with my version:\n",
    "\n",
    "1. My gamma priors on tau are more informative. This is because PyMC was having some computational issues with the Gamma(.001, .001) priors the professor used. I don't know if it's because of the sampling algorithm or if it's a problem with the new computational backend. I will look into it more later, for now I just want to get these examples up.\n",
    "\n",
    "2. I imputed the x values with a more informative prior for similar reasons. That Uniform(0, 500) prior seems kind of crazy to me, and I wanted to rule out more computational issues.\n",
    "\n",
    "3. I got rid of the separate definition of the intercept as alpha, it is now beta[0].\n",
    "\n",
    "I have not checked this model for any kind of correctness or compared the answers to the BUGS version. It may make no sense at all (considering the amount of divergences, it probably doesn't)! But I hope it gives you an idea for how to handle the missing data question on HW6, which I have confirmed works well in PyMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "30f99046-7740-4783-809d-1078c71e6586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 6)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that I added a 1 to the first value for x, this is for the intercept beta[0]\n",
    "x = [1.0, 8.0, 15.0, 22.0, np.nan, 36.0]\n",
    "y = np.loadtxt(\"./data/rats.txt\")\n",
    "y = np.concatenate((np.ones((y.shape[0], 1)), y), axis=1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7fb9f7d1-9be5-483f-bb59-c5c7525a919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create masked data\n",
    "y = y.copy()\n",
    "y = np.nan_to_num(y, nan=-1)\n",
    "y = np.ma.masked_values(y, value=-1)\n",
    "\n",
    "x = x.copy()\n",
    "x = np.nan_to_num(x, nan=-1)\n",
    "x = np.ma.masked_values(x, value=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33a6d842-182f-43d1-aa71-c74881f24a2f",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc-dev-py39/lib/python3.9/site-packages/pymc/model.py:1322: ImputationWarning: Data in x_imputed contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "/Users/aaron/mambaforge/envs/pymc-dev-py39/lib/python3.9/site-packages/pymc/model.py:1322: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [tau.c, beta.c, beta.tau, beta, x_imputed_missing, likelihood_missing]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='48000' class='' max='48000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [48000/48000 16:50<00:00 Sampling 4 chains, 13,220 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/mambaforge/envs/pymc-dev-py39/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc-dev-py39/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc-dev-py39/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "/Users/aaron/mambaforge/envs/pymc-dev-py39/lib/python3.9/site-packages/scipy/stats/_continuous_distns.py:624: RuntimeWarning: overflow encountered in _beta_ppf\n",
      "  return _boost._beta_ppf(q, a, b)\n",
      "Sampling 4 chains for 2_000 tune and 10_000 draw iterations (8_000 + 40_000 draws total) took 1017 seconds.\n",
      "There were 3422 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 3437 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 2927 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 3434 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    beta_c = pm.Normal(\"beta.c\", 0, sigma=10)\n",
    "\n",
    "    beta = pm.Normal(\"beta\", beta_c, sigma=10, shape=x.shape[0])\n",
    "\n",
    "    x_imputed = pm.Normal(\"x_imputed\", mu=20, sigma=10, observed=x)\n",
    "\n",
    "    mu = dot(beta, x_imputed)\n",
    "    likelihood = pm.Normal(\"likelihood\", mu, sigma=10, observed=y, shape=y.shape[0])\n",
    "\n",
    "    trace = pm.sample(\n",
    "        10000,\n",
    "        tune=2000,\n",
    "        cores=4,\n",
    "        init=\"jitter+adapt_diag\",\n",
    "        step=[pm.NUTS(target_accept=.9)]\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c7e97-c3eb-4c94-806d-e6d22605695a",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ce0da6-ec10-4609-b488-f3b77fb39598",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "can't impute data with pm.Data(mutable=True)? \n",
    "reading:\n",
    "https://github.com/pymc-devs/pymc/issues/4441\n",
    "https://github.com/pymc-devs/pymc/pull/5295\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
