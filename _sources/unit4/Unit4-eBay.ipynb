{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b8ed01a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import pymc as pm\n",
    "from pymc.math import invlogit\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ddac04",
   "metadata": {
    "tags": []
   },
   "source": [
    "# eBay Purchase Example*\n",
    "\n",
    "This example shows some of the effects different priors can have on your results.\n",
    "\n",
    "From [unit 4: eBay.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit4/eBay.odc).\n",
    "\n",
    "Associated lecture video: Unit 4 Lesson 17: eBay Purchase Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8609781a",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "You've decided to purchase a new Orbital Shaking Incubator for your research lab on eBay.\n",
    "\n",
    "Two sellers are offering this item for the same price, both with free shipping. Seller A has 95% positive feedback from 100 responders, while seller B has 100% positive feedback from 3 responders. We assume that all 103 responders are different, unrelated customers, to avoid dependent responses.\n",
    "\n",
    "From which seller should you order?\n",
    "\n",
    "That depends on your priors!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a211e514",
   "metadata": {},
   "source": [
    "```{note}\n",
    "I changed labels 1 and 2 in the model to A and B to align with the problem definition.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "799d31d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "pos_A = 95\n",
    "tot_A = 100\n",
    "\n",
    "tot_B = 3\n",
    "pos_B = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82a5734e",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [uniform_A, jeffrey_A, informative_A, ign_A, norm_A, uniform_B, jeffrey_B, informative_B, ign_B, norm_B]\n",
      "Sampling 4 chains for 2_000 tune and 4_000 draw iterations (8_000 + 16_000 draws total) took 97 seconds.\n",
      "There were 5242 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(0)\n",
      "Coordinates:\n",
      "    chain    int64 0 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(1)\n",
      "Coordinates:\n",
      "    chain    int64 1 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(2)\n",
      "Coordinates:\n",
      "    chain    int64 2 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(3)\n",
      "Coordinates:\n",
      "    chain    int64 3 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "# lots of problems in PyMC 4, probably need to redo later\n",
    "with pm.Model() as m:\n",
    "    # priors\n",
    "    priors_A = (\n",
    "        pm.Beta(\"uniform_A\", alpha=1, beta=1),\n",
    "        pm.Beta(\"jeffrey_A\", alpha=0.5, beta=0.5),\n",
    "        pm.Beta(\"informative_A\", alpha=30, beta=2),\n",
    "        pm.Deterministic(\n",
    "            \"zellner_A\", invlogit(pm.Uniform(\"ign_A\", lower=-1000, upper=1000))\n",
    "        ),\n",
    "        pm.LogitNormal(\"norm_A\", mu=3, sigma=1),\n",
    "    )\n",
    "\n",
    "    priors_B = (\n",
    "        pm.Beta(\"uniform_B\", alpha=1, beta=1),\n",
    "        pm.Beta(\"jeffrey_B\", alpha=0.5, beta=0.5),\n",
    "        pm.Beta(\"informative_B\", alpha=2.9, beta=0.1),\n",
    "        pm.Deterministic(\n",
    "            \"zellner_B\", invlogit(pm.Uniform(\"ign_B\", lower=-1000, upper=1000))\n",
    "        ),\n",
    "        pm.LogitNormal(\"norm_B\", mu=3, sigma=1),\n",
    "    )\n",
    "\n",
    "    # likelihoods\n",
    "    for A, B in zip(priors_A, priors_B):\n",
    "        prior_type = A.name.strip(\"_A\")\n",
    "\n",
    "        pm.Binomial(\"y_\" + A.name, n=tot_A, p=A, observed=pos_A)\n",
    "        pm.Binomial(\"y_\" + B.name, n=tot_B, p=B, observed=pos_B)\n",
    "\n",
    "        pm.Deterministic(\"diff_\" + prior_type, A - B)\n",
    "\n",
    "    # start sampling\n",
    "    trace = pm.sample(4000, tune=2000, target_accept=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e075ec",
   "metadata": {},
   "source": [
    "PyMC is deeply unhappy with some of these models but the results are the same as BUGS, so I'm going to leave well enough alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15414707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>uniform_A</th>\n",
       "      <td>0.941</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4591.0</td>\n",
       "      <td>4676.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeffrey_A</th>\n",
       "      <td>0.945</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.902</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4902.0</td>\n",
       "      <td>4345.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>informative_A</th>\n",
       "      <td>0.947</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.908</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5390.0</td>\n",
       "      <td>5352.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_A</th>\n",
       "      <td>0.949</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.910</td>\n",
       "      <td>0.983</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5345.0</td>\n",
       "      <td>4984.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniform_B</th>\n",
       "      <td>0.800</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.466</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4087.0</td>\n",
       "      <td>3307.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jeffrey_B</th>\n",
       "      <td>0.874</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.556</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>3419.0</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>informative_B</th>\n",
       "      <td>0.984</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.903</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3148.0</td>\n",
       "      <td>2495.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>norm_B</th>\n",
       "      <td>0.943</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4634.0</td>\n",
       "      <td>5387.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zellner_A</th>\n",
       "      <td>0.950</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4677.0</td>\n",
       "      <td>4801.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zellner_B</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>6690.0</td>\n",
       "      <td>16000.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_uniform</th>\n",
       "      <td>0.141</td>\n",
       "      <td>0.167</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>3867.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_jeffrey</th>\n",
       "      <td>0.072</td>\n",
       "      <td>0.152</td>\n",
       "      <td>-0.103</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4722.0</td>\n",
       "      <td>6495.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_informative</th>\n",
       "      <td>-0.037</td>\n",
       "      <td>0.051</td>\n",
       "      <td>-0.113</td>\n",
       "      <td>0.055</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7091.0</td>\n",
       "      <td>8013.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_zellner</th>\n",
       "      <td>-0.050</td>\n",
       "      <td>0.022</td>\n",
       "      <td>-0.095</td>\n",
       "      <td>-0.014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4712.0</td>\n",
       "      <td>4870.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff_norm</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.056</td>\n",
       "      <td>-0.082</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5065.0</td>\n",
       "      <td>6313.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   mean     sd  hdi_2.5%  hdi_97.5%  mcse_mean  mcse_sd  \\\n",
       "uniform_A         0.941  0.023     0.896      0.983      0.000    0.000   \n",
       "jeffrey_A         0.945  0.022     0.902      0.984      0.000    0.000   \n",
       "informative_A     0.947  0.020     0.908      0.981      0.000    0.000   \n",
       "norm_A            0.949  0.020     0.910      0.983      0.000    0.000   \n",
       "uniform_B         0.800  0.165     0.466      1.000      0.002    0.002   \n",
       "jeffrey_B         0.874  0.150     0.556      1.000      0.002    0.001   \n",
       "informative_B     0.984  0.047     0.903      1.000      0.000    0.000   \n",
       "norm_B            0.943  0.052     0.842      0.999      0.001    0.001   \n",
       "zellner_A         0.950  0.022     0.905      0.986      0.000    0.000   \n",
       "zellner_B         1.000  0.002     1.000      1.000      0.000    0.000   \n",
       "diff_uniform      0.141  0.167    -0.086      0.492      0.002    0.002   \n",
       "diff_jeffrey      0.072  0.152    -0.103      0.405      0.002    0.001   \n",
       "diff_informative -0.037  0.051    -0.113      0.055      0.000    0.000   \n",
       "diff_zellner     -0.050  0.022    -0.095     -0.014      0.000    0.000   \n",
       "diff_norm         0.006  0.056    -0.082      0.124      0.001    0.001   \n",
       "\n",
       "                  ess_bulk  ess_tail  r_hat  \n",
       "uniform_A           4591.0    4676.0    1.0  \n",
       "jeffrey_A           4902.0    4345.0    1.0  \n",
       "informative_A       5390.0    5352.0    1.0  \n",
       "norm_A              5345.0    4984.0    1.0  \n",
       "uniform_B           4087.0    3307.0    1.0  \n",
       "jeffrey_B           3419.0    2418.0    1.0  \n",
       "informative_B       3148.0    2495.0    1.0  \n",
       "norm_B              4634.0    5387.0    1.0  \n",
       "zellner_A           4677.0    4801.0    1.0  \n",
       "zellner_B           6690.0   16000.0    1.0  \n",
       "diff_uniform        4250.0    3867.0    1.0  \n",
       "diff_jeffrey        4722.0    6495.0    1.0  \n",
       "diff_informative    7091.0    8013.0    1.0  \n",
       "diff_zellner        4712.0    4870.0    1.0  \n",
       "diff_norm           5065.0    6313.0    1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, var_names=[\"~ign_A\", \"~ign_B\"], hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a434b7b",
   "metadata": {},
   "source": [
    "The results are pretty close to the professor's BUGS results:\n",
    "\n",
    "|           | mean     | sd       | MC_error | val2.5pc | median    | val97.5pc |\n",
    "|-----------|----------|----------|----------|----------|-----------|-----------|\n",
    "| diffps[1] | 0.1417   | 0.1649   | 4.93E-04 | -0.06535 | 0.1018    | 0.5448    |\n",
    "| diffps[2] | 0.06921  | 0.1485   | 4.63E-04 | -0.08247 | 0.01423   | 0.4774    |\n",
    "| diffps[3] | -0.03623 | 0.05252  | 1.70E-04 | -0.09355 | -0.04494  | 0.1144    |\n",
    "| diffps[4] | -0.05004 | 0.02177  | 7.02E-05 | -0.1003  | -0.04712  | -0.0164   |\n",
    "| diffps[5] | 0.00658  | 0.05593  | 1.73E-04 | -0.06808 | -0.005543 | 0.1526    |\n",
    "| p1[1]     | 0.9412   | 0.02319  | 7.40E-05 | 0.8882   | 0.9442    | 0.9778    |\n",
    "| p1[2]     | 0.9456   | 0.02235  | 7.13E-05 | 0.8944   | 0.9485    | 0.9808    |\n",
    "| p1[3]     | 0.9471   | 0.01937  | 6.09E-05 | 0.9031   | 0.9493    | 0.9782    |\n",
    "| p1[4]     | 0.9499   | 0.02169  | 7.04E-05 | 0.8997   | 0.9529    | 0.9836    |\n",
    "| p1[5]     | 0.9498   | 0.01973  | 5.96E-05 | 0.9043   | 0.9525    | 0.9804    |\n",
    "| p2[1]     | 0.7995   | 0.1632   | 4.89E-04 | 0.3982   | 0.8402    | 0.9938    |\n",
    "| p2[2]     | 0.8764   | 0.1468   | 4.56E-04 | 0.4694   | 0.9336    | 0.9999    |\n",
    "| p2[3]     | 0.9833   | 0.04892  | 1.58E-04 | 0.8344   | 0.9999    | 1         |\n",
    "| p2[4]     | 1        | 0.001891 | 5.84E-06 | 1        | 1         | 1         |\n",
    "|  p2[5]    | 0.9432   | 0.05234  | 1.66E-04 | 0.7986   | 0.9592    | 0.9935    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8dc43018",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(trace, var_names=[\"~ign_A\", \"~ign_B\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7852a167",
   "metadata": {},
   "source": [
    "I'd like to expand on this answer in the future, leaving it for now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430f0ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -p pytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d42df3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
