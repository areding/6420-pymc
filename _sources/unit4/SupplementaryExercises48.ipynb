{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ada150",
   "metadata": {},
   "source": [
    "# Supplementary Exercises 4.8\n",
    "\n",
    "## 7. Derive Jeffreys’ Priors for Poisson $\\lambda$, **Bernoulli** $p$, **and Geometric** $p$.\n",
    "\n",
    "Recall that Jeffreys’ prior for parameter $\\theta$ in the likelihood $f(x | \\theta)$ is defined as\n",
    "\n",
    "$$\\pi(\\theta) \\propto \\left| \\text{det}(I(\\theta)) \\right|^{1/2}$$\n",
    "\n",
    "where, for univariate parameters,\n",
    "\n",
    "$$I(\\theta) = E \\left[ \\left( \\frac{d \\log f(x | \\theta)}{d\\theta} \\right)^2 \\right] = -E \\left[ \\frac{d^2 \\log f(x | \\theta)}{d\\theta^2} \\right]$$\n",
    "\n",
    "and expectation is taken with respect to the random variable $X \\sim f(x | \\theta)$.\n",
    "\n",
    "**(a) Show that Jeffreys’ prior for Poisson distribution** $f(x | \\lambda) = \\frac{\\lambda^x}{x!} e^{-\\lambda}$, $\\lambda \\geq 0$, **is** $\\pi(\\lambda) = \\sqrt{\\frac{1}{\\lambda}}$.\n",
    "\n",
    "**(b) Show that Jeffreys’ prior for Bernoulli distribution** $f(x | p) = p^x (1 - p)^{1-x}$, $0 \\leq p \\leq 1$, **is** $\\pi(p) \\propto \\frac{1}{\\sqrt{p(1-p)}}$, which is the beta $\\text{Be}(1/2, 1/2)$ distribution (or Arcsin distribution).\n",
    "\n",
    "**(c) Show that Jeffreys’ prior for Geometric distribution** $f(x | p) = (1 - p)^{x-1} p$, $x = 1, 2, \\ldots$ ; $0 \\leq p \\leq 1$, **is** $\\pi(p) \\propto \\frac{1}{p \\sqrt{1-p}}$.\n",
    "\n",
    "---\n",
    "\n",
    "**7. Derive Jeffreys’ Priors for Poisson** $\\lambda$, **Bernoulli** $p$, **and Geometric** $p$.\n",
    "\n",
    "**(a)**\n",
    "For the Poisson distribution with likelihood function:\n",
    "$$f(x | \\lambda) = \\frac{\\lambda^x e^{-\\lambda}}{x!}$$\n",
    "\n",
    "First, we differentiate the log-likelihood with respect to $\\lambda$:\n",
    "\n",
    "$$\\frac{d}{d\\lambda} \\log \\left( \\frac{\\lambda^x e^{-\\lambda}}{x!} \\right) = \\frac{d}{d\\lambda} (x \\log \\lambda - \\lambda)$$\n",
    "\n",
    "Which gives:\n",
    "\n",
    "$$\\frac{x}{\\lambda} - 1$$\n",
    "\n",
    "Now, the Fisher Information $I(\\lambda)$ is given by:\n",
    "\n",
    "$$I(\\lambda) = E\\left[ \\left( \\frac{x}{\\lambda} - 1 \\right)^2 \\right] = \\frac{E[x^2]}{\\lambda^2} - \\frac{2E[x]}{\\lambda} + 1$$\n",
    "\n",
    "Given that $E[x^2] = Var(x) + (E[x])^2$ and for a Poisson distribution, $E[x] = \\lambda$ and $Var(x) = \\lambda$:\n",
    "\n",
    "$$E[x^2] = \\lambda + \\lambda^2$$\n",
    "\n",
    "Substituting this in, we get:\n",
    "\n",
    "$$I(\\lambda) = \\frac{1}{\\lambda}$$\n",
    "\n",
    "Thus, the Jeffreys’ prior is:\n",
    "\n",
    "$$\\pi(\\lambda) \\propto \\sqrt{\\frac{1}{\\lambda}}$$\n",
    "\n",
    "**(b)**\n",
    "For the Bernoulli distribution:\n",
    "$$f(x | p) = p^x (1-p)^{1-x}$$\n",
    "\n",
    "The log-likelihood is:\n",
    "\n",
    "$$L = x \\log(p) + (1 - x) \\log(1 - p)$$\n",
    "\n",
    "Differentiating $L$ with respect to $p$ we get:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial p} = \\frac{x}{p} - \\frac{1-x}{1-p}$$\n",
    "\n",
    "And the second derivative is:\n",
    "\n",
    "$$\\frac{\\partial^2 L}{\\partial p^2} = -\\frac{x}{p^2} - \\frac{1-x}{(1-p)^2}$$\n",
    "\n",
    "For a Bernoulli distribution, $E[x] = p$. The Fisher Information $I(p)$ is:\n",
    "\n",
    "$$I(p) = \\frac{1}{p(1-p)}$$\n",
    "\n",
    "So, the Jeffreys’ prior is:\n",
    "\n",
    "$$\\pi(p) \\propto \\frac{1}{\\sqrt{p(1-p)}}$$\n",
    "\n",
    "**(c)**\n",
    "For the Geometric distribution:\n",
    "\n",
    "$$f(x | p) = (1-p)^{x-1} p$$\n",
    "\n",
    "The log-likelihood is:\n",
    "\n",
    "$$L = (x-1) \\log(1-p) + \\log(p)$$\n",
    "\n",
    "Differentiating $L$ with respect to $p$:\n",
    "\n",
    "$$\\frac{\\partial L}{\\partial p} = \\frac{1}{p} - \\frac{x-1}{1-p}$$\n",
    "\n",
    "And the second derivative is:\n",
    "\n",
    "$$\\frac{\\partial^2 L}{\\partial p^2} = -\\frac{1}{p^2} - \\frac{x-1}{(1-p)^2}$$\n",
    "\n",
    "For a Geometric distribution, $E[x] = \\frac{1}{p}$. The Fisher Information $I(p)$ is:\n",
    "\n",
    "$$I(p) = \\frac{1}{p^2(1-p)}$$\n",
    "\n",
    "So, the Jeffreys’ prior is:\n",
    "\n",
    "$$\\pi(p) \\propto \\frac{1}{p \\sqrt{1-p}}$$\n",
    "\n",
    "## 14. Jigsaw\n",
    "\n",
    "An experiment with a sample of 18 nursery-school children involved the elapsed time required to put together a small jigsaw puzzle. The times were: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eec88db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [3.1, 3.2, 3.4, 3.6, 3.7, 4.2, 4.3, 4.5, 4.7,\n",
    " 5.2, 5.6, 6.0, 6.1, 6.6, 7.3, 8.2, 10.8, 13.6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3161ce82",
   "metadata": {},
   "source": [
    "Assume that data are coming from a normal distribution $N (\\mu, \\sigma^2)$ with $\\sigma^2 = 8$. For parameter $\\mu$, set a normal prior with mean 5 and variance 6.\n",
    "\n",
    "------------------\n",
    "\n",
    "(a) Find the Bayes estimator and 95% credible set for population mean $\\mu$.\n",
    "\n",
    "We can define our model like this:\n",
    "$$\n",
    "\\begin{align}\n",
    "x_i|\\mu &\\sim N(\\mu, 8) \\\\\n",
    "\\mu & \\sim N(5, 6)\n",
    "\\end{align}\n",
    "$$\n",
    "This is the Normal-Normal conjugate pair for a fixed variance and random mean, with $n=18$ and $\\bar{X} \\approx 5.78333$\n",
    "\n",
    "Our posterior is then:\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pi(\\theta|x) &\\sim N\\left(\\frac{\\tau^2}{\\tau^2 +\\sigma^2/n}\\bar{X} + \\frac{\\sigma^2/n}{\\tau^2 + \\sigma^2/n}\\mu_0, \\frac{\\tau^2\\sigma^2/n}{\\tau^2+ \\sigma^2/n}\\right) \\\\\n",
    "& \\sim N(\\frac{6}{6 + 8/18}\\bar{X} + \\frac{8/18}{6 + 8/18}(5), \\frac{6(8/18)}{6+8/18}) \\\\\n",
    "& \\sim N(5.72931, 0.41379)\n",
    "\\end{align}\n",
    "$$\n",
    "Our Bayes estimator will be the posterior mean, 5.72931.\n",
    "\n",
    "The 95% equitailed credible set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64f6845a-0f8f-40ca-8c2b-1f6ab51cb720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.468533554544652, 6.990086445455348)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as ss\n",
    "\n",
    "alpha = .05\n",
    "mean = 5.72931\n",
    "var = .41379\n",
    "\n",
    "post = ss.norm(loc=mean, scale=var**.5)\n",
    "\n",
    "post.ppf(alpha/2), post.ppf(1 - alpha/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be1184-22af-4055-8f90-ded660f916cb",
   "metadata": {},
   "source": [
    "The HPD credible set will be the same for the normal distribution because of symmetry:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa761613-6f5d-4c7b-bc87-56758b0cd703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.46853355, 6.99008645])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import fsolve\n",
    "\n",
    "def conditions(x, post, alpha):\n",
    "    lwr, upr = x\n",
    "\n",
    "    cond_1 = post.pdf(upr) - post.pdf(lwr)\n",
    "    cond_2 = post.cdf(upr) - post.cdf(lwr) - (1 - alpha)\n",
    "    \n",
    "    return cond_1, cond_2\n",
    "\n",
    "fsolve(conditions, (4.5, 7.0), args=(post, alpha))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22eb4e4b",
   "metadata": {},
   "source": [
    "(b) Find the posterior probability of hypothesis $H_0 : \\mu \\leq 5$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c931b0d2-48a1-4eae-b161-a383f4bb9844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12844704607549606"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post.cdf(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5256a824-049a-4ddc-8f25-e5f318bc7479",
   "metadata": {},
   "source": [
    "(c) What is your prediction for a single future observation?\n",
    "\n",
    "Since we only want a single future observation, we can use this from Greg's U4L13 notes (linked under the lecture videos):\n",
    "\n",
    "$$\n",
    "\\hat{X}_{n+1} = \\int_\\theta \\mu(\\theta) \\pi(\\theta \\mid x_i) d\\theta\n",
    "$$\n",
    "\n",
    "where $\\mu(\\theta) = \\mathbb{E}[X] = \\int x f(x \\mid \\theta) dx$ is the mean of the original likelihood (the distribution of $X|\\theta$).\n",
    "\n",
    "We can use the [```.expect()```](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.rv_continuous.expect.html) method on our posterior to calculate this single value, since it will take the expectation of a function with respect to our posterior. Although in the model we treat the mean of the likelihood as unknown, here we can use the mean of $\\mu$ (the mean of the prior on $\\mu$).\n",
    "\n",
    "As the original hints for the solution said, this will equal the posterior mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e5bddec-4fe7-4bfa-8d28-a4d7cdd94791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.729310000000003"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define likelihood\n",
    "lik = ss.norm(loc=5, scale=8**.5)\n",
    "\n",
    "post.expect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df329374-a2f2-49b1-a05e-f8b6e1911589",
   "metadata": {},
   "source": [
    "A PyMC solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c4681b9e-64d8-47e2-a27b-6218a58009e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [mu]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='24000' class='' max='24000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [24000/24000 00:00&lt;00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 1 seconds.\n",
      "Sampling: [lik]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='20000' class='' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [20000/20000 00:00&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "\n",
    "with pm.Model() as m:\n",
    "    mu_prior = pm.Normal(\"mu\", 5, sigma=6**.5)\n",
    "\n",
    "    likelihood = pm.Normal(\"lik\", mu_prior, sigma=8**.5, observed=data)\n",
    "\n",
    "    trace = pm.sample(5000)\n",
    "    pm.sample_posterior_predictive(trace, extend_inferencedata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9c1694a6-89a7-41ea-8991-80b2d7b23491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mu</th>\n",
       "      <td>5.721</td>\n",
       "      <td>0.647</td>\n",
       "      <td>4.503</td>\n",
       "      <td>7.033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean     sd  hdi_2.5%  hdi_97.5%\n",
       "mu  5.721  0.647     4.503      7.033"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, hdi_prob=.95, kind=\"stats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6bc2044f-1b77-485d-9981-04ca76ed4ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataArray ()>\n",
      "array(5.72300883)\n"
     ]
    }
   ],
   "source": [
    "print(trace.posterior_predictive.to_array().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27c10ba-91e0-4382-bfb9-b64653c1af54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "formats": "ipynb,py,md",
   "main_language": "python"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
