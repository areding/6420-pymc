{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6a46bbf-b944-46bb-89df-11703fe86e1f",
   "metadata": {},
   "source": [
    "# 12. Bayesian Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3c384-1adc-4448-a0d7-9fcde2620fd4",
   "metadata": {},
   "source": [
    "First, I recommend checking out 3blue1brown's [video on Bayes' factor](https://www.youtube.com/watch?v=lG4VkPoG3ko) to help with intuition. There is a similar example in Professor Vidakov's [statistics book](https://statbook.gatech.edu): {cite:t}`vidakovic2017engineering` page 103."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4ec021-f475-4dfe-9f06-a4e93fd094f7",
   "metadata": {},
   "source": [
    "Unlike the classical approach, Bayesian testing doesn't prioritize the null hypothesis. Instead, we calculate the posterior probabilities for both hypotheses, then choose the one with the larger posterior probability.\n",
    "\n",
    "## Point masses\n",
    "\n",
    "The professor notes that your overall prior needs to contain the point mass representing your precise null hypothesis. \n",
    "\n",
    "What the professor means here is that you can only test a hypothesis where your prior allows for a probability greater than 0. So if your prior is just a continuous distribution, the probability at any given point is 0. At a high level, if your prior doesn't contain your hypothesis, you are essentially ruling out the hypothesis before you even build the rest of your model. Without mixing in the point mass, you've already predetermined that your hypothesis is impossible.\n",
    "\n",
    "That's why he mixes that point mass and the \"spread\" distribution; you need a discrete distribution to test a specific point.\n",
    "\n",
    "## Scales for the strength of evidence\n",
    "\n",
    "The professor uses Jeffrey's scale ({cite:t}`jeffreystheoryofprob` Appendix B) in the lecture. \n",
    "\n",
    "| Grade | K Value       | Interpretation                                      |\n",
    "|------|--------------|:----------------------------------------------------|\n",
    "| 0     | $K > 1$         | Null hypothesis supported.                           |\n",
    "| 1     | $1 > K > 10^{-1/2}$ | Evidence against q, but not worth more than a bare mention. |\n",
    "| 2     | $10^{-1/2} > K > 10^{-1}$ | Evidence against q substantial.                      |\n",
    "| 3     | $10^{-1} > K > 10^{-3/2}$ | Evidence against q strong.                           |\n",
    "| 4     | $10^{-3/2} > K > 10^{-2}$| Evidence against q very strong.                      |\n",
    "| 5     | $10^{-2} > K$     | Evidence against q decisive.                         |\n",
    "\n",
    "This scale is subjective, though. There are other ones out there: the Kass & Raftery scale ({cite:t}`kass1995bayes`) and the Lee and Wagenmakers scale ({cite:t}`lee2013bayesian`) are two alternatives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1d5b16-85e1-417b-a80a-364f52e122ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
