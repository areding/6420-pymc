# Bayesian inference

For now, this is just a list of what I consider the most important parts of the unit. This is a lot of stuff, so don't worry if you don't understand it all right away. It will sink in as we go through the course.

## Distributions

Understand what a random variable is.

The most commonly used distributions in this class:

### Continuous

- Normal
- Uniform
- Exponential
- Gamma
- Beta
- Multivariate normal
- Weibull
- Student's *t*-distribution

### Discrete

- Bernoulli
- Binomial
- Poisson
- Multinomial

There's no need to memorize individual CDFs and PDFs, but understand the difference between the two and how they relate.

Understand that there are different ways to parameterize distributions and what those parameters mean for different distributions (keywords: shape, rate, scale, location). Probably the most-common mistake in this course is mistaking precision for variance in the normal distribution!

Joint distributions and conditional distributions will be important for Units 4 and 5.

## Bayes' theorem and the likelihood principle

Understand the likelihood principle and how Bayes' theorem is applied to distributions (before we were practicing with probabilities).

Be aware that conjugate distributions exist and check out the table in the statbook.

## Bayesian inference in conjugate cases.

This chapter should really be called "Communicating information about the posterior."

### Point estimates

Mean, median, MAP.


### Credible intervals (aka credible sets)

See the Gamma Gamma example.

### Bayes' risk and estimation



### Bayesian testing and Bayes' Factor




## Prior elicitation

### Priors

### Non-informative priors

## Empirical Bayes

### Parametric

### Non-parametric



