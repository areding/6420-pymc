{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5554edbc",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymc as pm\n",
    "\n",
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253075e",
   "metadata": {},
   "source": [
    "# Taste of cheese\n",
    "\n",
    "Adapted from [Unit 6: cheese.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit6/cheese.odc).\n",
    "\n",
    "The link in the original .odc file is dead. I downloaded the data from [here](https://www3.nd.edu/~busiforc/handouts/Data%20and%20Stories/multicollinearity/Cheese%20Taste/Cheddar%20Cheese%20Data.html) and have a copy [here](https://raw.githubusercontent.com/areding/6420-pymc/main/data/cheese.csv)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bef7810c",
   "metadata": {},
   "source": [
    "Associated lecture videos: Unit 6, Lessons 5 and 8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6984bec3",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "\n",
    "As cheddar cheese matures, a variety of chemical processes take place. The taste of matured cheese is related to the concentration of several chemicals in the final product. In a study of cheddar cheese from the LaTrobe Valley of Victoria, Australia, samples of cheese were analyzed for their chemical composition and were subjected to taste tests. Overall taste scores were obtained by combining the scores from several tasters.\n",
    "\n",
    "Can the score be predicted well by the predictors: Acetic, H2S, and Lactic?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dd94c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/cheese.csv\", index_col=0)\n",
    "X = data[[\"Acetic\", \"H2S\", \"Lactic\"]].to_numpy()\n",
    "# add intercept column to X\n",
    "X_aug = np.concatenate((np.ones((X.shape[0], 1)), X), axis=1)\n",
    "y = data[\"taste\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3467bf7",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [beta, tau]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 20 seconds.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(0)\n",
      "Coordinates:\n",
      "    chain    int64 0 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(1)\n",
      "Coordinates:\n",
      "    chain    int64 1 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(2)\n",
      "Coordinates:\n",
      "    chain    int64 2 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n",
      "Chain <xarray.DataArray 'chain' ()>\n",
      "array(3)\n",
      "Coordinates:\n",
      "    chain    int64 3 reached the maximum tree depth. Increase `max_treedepth`, increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    # associate data with model (this makes prediction easier)\n",
    "    X_data = pm.Data(\"X\", X_aug, mutable=True)\n",
    "    y_data = pm.Data(\"y\", y, mutable=False)\n",
    "\n",
    "    # priors\n",
    "    beta = pm.Normal(\"beta\", mu=0, sigma=1000, shape=X.shape[1] + 1)\n",
    "    tau = pm.Gamma(\"tau\", alpha=0.001, beta=0.001)\n",
    "    sigma = 1 / pm.math.sqrt(tau)\n",
    "\n",
    "    mu = pm.math.dot(X_data, beta)\n",
    "\n",
    "    # likelihood\n",
    "    taste_score = pm.Normal(\"taste_score\", mu=mu, sigma=sigma, observed=y_data)\n",
    "\n",
    "    # start sampling\n",
    "    trace = pm.sample(5000, target_accept=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f1b9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta[0]</th>\n",
       "      <td>-28.990</td>\n",
       "      <td>20.315</td>\n",
       "      <td>-69.893</td>\n",
       "      <td>10.876</td>\n",
       "      <td>0.230</td>\n",
       "      <td>0.162</td>\n",
       "      <td>7855.0</td>\n",
       "      <td>9062.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[1]</th>\n",
       "      <td>0.350</td>\n",
       "      <td>4.593</td>\n",
       "      <td>-9.017</td>\n",
       "      <td>9.113</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0.038</td>\n",
       "      <td>7508.0</td>\n",
       "      <td>9073.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[2]</th>\n",
       "      <td>3.896</td>\n",
       "      <td>1.289</td>\n",
       "      <td>1.356</td>\n",
       "      <td>6.433</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.009</td>\n",
       "      <td>10251.0</td>\n",
       "      <td>10699.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta[3]</th>\n",
       "      <td>19.712</td>\n",
       "      <td>9.006</td>\n",
       "      <td>1.722</td>\n",
       "      <td>37.333</td>\n",
       "      <td>0.089</td>\n",
       "      <td>0.064</td>\n",
       "      <td>10223.0</td>\n",
       "      <td>10986.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tau</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10150.0</td>\n",
       "      <td>10635.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean      sd  hdi_2.5%  hdi_97.5%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "beta[0] -28.990  20.315   -69.893     10.876      0.230    0.162    7855.0   \n",
       "beta[1]   0.350   4.593    -9.017      9.113      0.053    0.038    7508.0   \n",
       "beta[2]   3.896   1.289     1.356      6.433      0.013    0.009   10251.0   \n",
       "beta[3]  19.712   9.006     1.722     37.333      0.089    0.064   10223.0   \n",
       "tau       0.010   0.003     0.005      0.015      0.000    0.000   10150.0   \n",
       "\n",
       "         ess_tail  r_hat  \n",
       "beta[0]    9062.0    1.0  \n",
       "beta[1]    9073.0    1.0  \n",
       "beta[2]   10699.0    1.0  \n",
       "beta[3]   10986.0    1.0  \n",
       "tau       10635.0    1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a5744e",
   "metadata": {},
   "source": [
    "Results are pretty close to OpenBUGS:\n",
    "\n",
    "|         mean |     sd   |        MC_error |   val2.5pc | median  |   val97.5pc | start   | sample |        |\n",
    "|--------------|----------|-----------------|------------|---------|-------------|---------|--------|--------|\n",
    "| beta0        | -29.75   | 20.24           | 0.7889     | -70.06  | -29.75      | 11.11   | 1000   | 100001 |\n",
    "| beta1        | 0.4576   | 4.6             | 0.189      | -8.716  | 0.4388      | 9.786   | 1000   | 100001 |\n",
    "| beta2        | 3.906    | 1.291           | 0.02725    | 1.345   | 3.912       | 6.47    | 1000   | 100001 |\n",
    "| beta3        | 19.79    | 8.893           | 0.2379     | 2.053   | 19.88       | 37.2    | 1000   | 100001 |\n",
    "| tau          | 0.009777 | 0.002706        | 2.29E-05   | 0.00522 | 0.009528    | 0.01575 | 1000   | 100001 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ffb987",
   "metadata": {},
   "source": [
    "PyMC gives some warnings about the model unless we increase the ```target_accept``` parameter of ```pm.sample```, while BUGS doesn't. This is because PyMC uses more diagnostics to check if there are any problems with its exploration of the parameter space. Divergences indicate bias in the results. BUGS will happily run this model without reporting any problems, but it doesn't mean that there aren't any.\n",
    "\n",
    "For further reading, check out [Diagnosing Biased Inference with Divergences](https://docs.pymc.io/en/v3/pymc-examples/examples/diagnostics_and_criticism/Diagnosing_biased_Inference_with_Divergences.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db0941c",
   "metadata": {},
   "source": [
    "It looks like there are multiple ways to get predictions on out-of-sample data in PyMC. The easiest way is to set up a shared variable using pm.Data in the original model, then using pm.set_data to change to the new observations before calling pm.sample_posterior_predictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e01d45",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "# single prediction on out-of-sample data\n",
    "new_obs = np.array([[1.0, 5.0, 7.1, 1.5]])\n",
    "pm.set_data({\"X\": new_obs}, model=m)\n",
    "ppc = pm.sample_posterior_predictive(trace, model=m, predictions=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305f88ce-fdad-4e97-9aa3-4387b4e3b389",
   "metadata": {},
   "source": [
    "The default behavior now is to give one prediction per y-value. The professor often asks for a single prediction based on the new data; the equivalent here would be to take the mean of the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0b18eb-c91f-492b-b726-b293834fc9d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean            29.995100\n",
       "sd              11.176933\n",
       "hdi_2.5%         7.997000\n",
       "hdi_97.5%       52.008733\n",
       "mcse_mean        0.083867\n",
       "mcse_sd          0.059567\n",
       "ess_bulk     17710.000000\n",
       "ess_tail     18567.166667\n",
       "r_hat            1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(ppc.predictions, hdi_prob=0.95).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "42361a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Sat Mar 18 2023\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.0\n",
      "IPython version      : 8.9.0\n",
      "\n",
      "pytensor: 2.10.1\n",
      "\n",
      "pandas    : 1.5.3\n",
      "numpy     : 1.24.2\n",
      "matplotlib: 3.6.3\n",
      "pymc      : 5.1.1\n",
      "arviz     : 0.14.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -p pytensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef9fb5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
