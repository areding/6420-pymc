{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f3ae63-43a8-4a3e-a5f5-37ed838f0ac8",
   "metadata": {},
   "source": [
    "# 16. Multinomial Logit\n",
    "\n",
    "Multinomial logit models are a generalization of logistic regression when there are more than 2 categories in the response. Assume **K** possible categories and **N** independent observations.\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_i & \\sim \\text{Multinomial}(\\mathbf{p}_i , 1), \\qquad i=1,\\dots,N\\\\\n",
    "\\mathbf{p}_i & = (p_{i1}, p_{i2}, \\dots , p_{iK}) \\\\\n",
    "y_i & = (y_{i1}, y_{i2}, \\dots , y_{iK}),\\; y_{ij}=1,\\; y_{ik}=0 \\;\\text{for } k\\neq j,\\; j \\in \\{1,\\dots,K\\}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The second parameter in the Multinomial distribution is the number of trials, which is $n = 1$ in the case of Multinomial logit. \n",
    "\n",
    "For example, the $i$‑th response could be $y_i = (0,0,0,1,0)$, meaning the 4th category is true and categories 1, 2, 3, and 5 are false:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_i & = (0,0,0,1,0) \\\\\n",
    "K & = 5 \\\\\n",
    "y_{i4} & = 1 \\\\\n",
    "y_{ik} & = 0 \\quad \\text{for } k \\neq 4 \\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Similar to the probability $p$ in a logistic regression for predicting category 1 over category 0, a vector of probabilities $\\mathbf{p}_i = (p_{i1}, p_{i2}, \\dots , p_{iK})$ is produced in the Multinomial logit model. To obtain these probabilities, the linear combination of $\\beta$ coefficients and $x$ predictors is calculated for each category into $\\eta$, and the $\\eta$’s are normalized using the [softmax function](https://en.wikipedia.org/wiki/Softmax_function) so that the sum of the probabilities equals 1:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\eta_{ij} & = \\beta_{0j} + \\beta_{1j} x_{i1} + \\dots + \\beta_{p-1,j} x_{i,p-1}\\\\\n",
    "p_{ij} & = \\frac{e^{\\eta_{ij}}}{\\sum_{k=1}^K e^{\\eta_{ik}}}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "There is a $\\beta$ coefficient for each category $j$ and each predictor. Putting it all together, the Bayesian model is:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "y_i & \\sim \\text{Multinomial}(\\mathbf{p}_i , 1) && \\text{likelihood}\\\\[4pt]\n",
    "\\eta_{ij} & = \\beta_{0j} + \\beta_{1j} x_{i1} + \\dots + \\beta_{p-1,j} x_{i,p-1} && \\text{deterministic} \\\\[4pt]\n",
    "p_{ij} & = \\frac{e^{\\eta_{ij}}}{\\sum_{k=1}^K e^{\\eta_{ik}}} && \\text{deterministic} \\\\[4pt]\n",
    "\\beta_{ij} & \\sim N(0,\\sigma_j^2) && \\text{prior}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Authors\n",
    "\n",
    "Jason Naramore, August 2024."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583e5915",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
