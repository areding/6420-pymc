{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5199f38",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import pymc as pm\n",
    "from pymc.math import log, sqr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dab390",
   "metadata": {},
   "source": [
    "# The Zero Trick and Custom Likelihoods*\n",
    "\n",
    "## Zero-trick Jeremy\n",
    "\n",
    "This introduces the \"zero trick\", which is a method for specifying custom likelihoods in BUGS. For a more detailed treatment of these methods, see {cite:t}```ntzoufras2009bayesian```, page 276, which is where I got this explanation. These tricks are unnecessary in PyMC since we can just define custom distributions directly, but they do seem to work.\n",
    "\n",
    "Adapted from [Unit 6: zerotrickjeremy.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit6/zerotrickjeremy.odc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbf22cd-65e7-400e-9f60-0bc3ed9c3799",
   "metadata": {},
   "source": [
    "Here's the model we're using:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "X_i \\mid \\theta &\\sim N(\\theta, 80) \\\\\n",
    "\\theta &\\sim N(110, 120)\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268b05c-3242-4925-bf4c-0e9fcb95a756",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "Of course, BUGS can handle this model just fine. But, let's pretend for a moment that there is no built-in normal distribution. The zero trick takes advantages of some properties of the Poisson distribution to recreate an arbitrary likelihood.\n",
    "\n",
    "Given a log-likelihood of the form $l_i = \\log f(y; \\theta)$,\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "f(y | \\theta) &= \\prod_{i=1}^{n} e^{l_i} && \\text{Log-likelihood to likelihood.}\\\\\n",
    "&= \\prod_{i=1}^{n} \\frac{e^{-(-l_i)}(-l_i)^0}{0!} && \\text{Matching the form of the Poisson PMF.} \\\\\n",
    "&= \\prod_{i=1}^{n} f_P(0; -l_i) && \\text{Poisson evaluated at zero with mean $-l_i$.}\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d36843-3623-4f7b-bde4-5aec9975ed4f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "–{cite:t}```ntzoufras2009bayesian``` page 276.\n",
    "\n",
    "But the rate, $\\lambda$, can't be negative. So we need to add a constant, C, to keep that from happening.\n",
    " \n",
    "The normal log-likelihood is:\n",
    "\n",
    "$$l_i = -0.5 \\log(2\\pi) - \\log(\\sigma^2) - \\frac{(y_i - \\mu_i)^2}{2\\sigma^2}$$\n",
    "\n",
    "But the constant terms won't affect the posterior.\n",
    "\n",
    "Here's the model in PyMC:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b99d7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 98\n",
    "μ = 110\n",
    "σ = 80**0.5\n",
    "τ = 120**0.5\n",
    "C = 10000\n",
    "\n",
    "inits = {\"θ\": 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258031fa",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [θ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0201bcfcb7184ab3b521194ac9a59e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 1 seconds.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    θ = pm.Flat(\"θ\")\n",
    "\n",
    "    λ1 = pm.Deterministic(\"λ1\", log(σ) + 0.5 * sqr(((y - θ) / σ)) + C)\n",
    "    λ2 = pm.Deterministic(\"λ2\", log(τ) + 0.5 * sqr(((θ - μ) / τ)) + C)\n",
    "\n",
    "    z1 = pm.Poisson(\"z1\", λ1, observed=0)\n",
    "    z2 = pm.Poisson(\"z2\", λ2, observed=0)\n",
    "\n",
    "    trace = pm.sample(5000, tune=1000, initvals=inits, target_accept=0.88)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dba6172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>θ</th>\n",
       "      <td>102.742</td>\n",
       "      <td>6.841</td>\n",
       "      <td>89.26</td>\n",
       "      <td>115.994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mean     sd  hdi_2.5%  hdi_97.5%\n",
       "θ  102.742  6.841     89.26    115.994"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, hdi_prob=0.95, var_names=\"θ\", kind=\"stats\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28f71b2",
   "metadata": {},
   "source": [
    "## Custom likelihoods in PyMC\n",
    "\n",
    "PyMC is a lot more flexible. For one, many more built-in [distributions](https://www.pymc.io/projects/docs/en/stable/api/distributions.html) are available, including mixtures and zero-inflated models, which is where I've seen the zero trick used most often ({cite:t}```karlisfootball```, {cite:t}```ntzoufras2009bayesian``` page 288).\n",
    "\n",
    "If you need a custom likelihood, take a look at the [pm.Potential](https://www.pymc.io/projects/docs/en/stable/api/generated/pymc.Potential.html) or [pm.CustomDist](https://www.pymc.io/projects/docs/en/stable/api/distributions/generated/pymc.CustomDist.html) classes. `pm.Potential` is used to adjust the likelihood, as we can see in the censored model ahead in [Unit 8.6](https://areding.github.io/6420-pymc/unit8/Unit8-tte-gastric.html). For now, let's take a look at how to use `pm.CustomDist`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c77c4f5",
   "metadata": {},
   "source": [
    "### `pm.CustomDist` Motivating Example: Survival Model\n",
    "\n",
    "We can alternatively build the survival model in in [Unit 6.9](https://areding.github.io/6420-pymc/unit6/Unit6-censoring.html) with the custom distribution based on this [post](https://www.pymc.io/projects/docs/en/stable/guides/Probability_Distributions.html#custom-distributions):\n",
    "\n",
    "$$f(c,t) = \\begin{cases} \n",
    "      \\exp(-\\lambda t) & \\text{if } c = 1 \\\\\n",
    "      \\lambda \\exp(-\\lambda t) & \\text{if } c = 0 \\\\\n",
    "   \\end{cases}$$\n",
    "\n",
    "`c` is an indicator variable. The data point is censored if `c=0`. When the point is not censored, the probability distribution is exponential. When the point is censored, the probability is the exponential distribution's complementary CDF, which accounts for the probability to the right of the censored point.\n",
    "\n",
    "To build this as a custom distribution, we create a `logp` or log-probability function, as PyMC prefers to work with log-probabilities. One tricky part for this distribution is that both observed data arrays (`t` and `c`) need to be concatenated into a matrix as input into the `observed` argument. We can see the summary results match those on [Unit 6.9](https://areding.github.io/6420-pymc/unit6/Unit6-censoring.html), which uses the different `pm.Censored` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d693b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [λ]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe72f2968e234d5d84c6cfc45e9abcdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 1 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>λ</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>7786.0</td>\n",
       "      <td>11573.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>μ</th>\n",
       "      <td>51.157</td>\n",
       "      <td>22.767</td>\n",
       "      <td>20.026</td>\n",
       "      <td>90.397</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.613</td>\n",
       "      <td>7786.0</td>\n",
       "      <td>11573.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean      sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  ess_tail  \\\n",
       "λ   0.023   0.008   0.008    0.038       0.00    0.000    7786.0   11573.0   \n",
       "μ  51.157  22.767  20.026   90.397       0.26    0.613    7786.0   11573.0   \n",
       "\n",
       "   r_hat  \n",
       "λ    1.0  \n",
       "μ    1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# gamma dist parameters\n",
    "α = 0.01\n",
    "β = 0.1\n",
    "\n",
    "# observed life within experiment dates\n",
    "t = np.array([2, 72, 51, 60, 33, 27, 14, 24, 4, 21])\n",
    "# censored indicator\n",
    "c = np.array([1,  0,  1,  0,  1,  1,  1,  1, 1,  0])\n",
    "# CustomDist requires all data to be together in a matrix\n",
    "val = np.concat([[t],[c]])\n",
    "\n",
    "# log-probability of custom distribution\n",
    "def logp(value, lam):\n",
    "    t = value[0,:]\n",
    "    c = value[1,:]\n",
    "    return (c * log(lam) - lam * t).sum()\n",
    "\n",
    "with pm.Model() as m:\n",
    "    λ = pm.Gamma(\"λ\", α, β)\n",
    "    μ = pm.Deterministic(\"μ\", 1 / λ)\n",
    "    \n",
    "    exp_surv = pm.CustomDist('exp_surv', λ, logp=logp, observed=val)\n",
    "\n",
    "    trace = pm.sample(5000)\n",
    "\n",
    "az.summary(trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdc0192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Fri Jun 13 2025\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.13.3\n",
      "IPython version      : 9.2.0\n",
      "\n",
      "pytensor: 2.30.3\n",
      "\n",
      "pymc : 5.22.0\n",
      "numpy: 2.2.6\n",
      "arviz: 0.21.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -p pytensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
