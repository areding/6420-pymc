{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47db427c",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import numpy as np\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fa8d0f",
   "metadata": {},
   "source": [
    "# Missing Data*\n",
    "\n",
    "## Dugongs\n",
    "This example is the first example of dealing with missing data.\n",
    "\n",
    "It is adapted from [Unit 6: dugongsmissing.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit6/dugongsmissing.odc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff800ef8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Problem statement\n",
    "Carlin and Gelfand (1991) investigated the age (x) and length (y) of 27 captured dugongs (sea cows). Estimate parameters in a nonlinear growth model.\n",
    "\n",
    "### References\n",
    "\n",
    "Data provided by Ratkowsky (1983).\n",
    "\n",
    "Carlin, B. and Gelfand, B. (1991). An Iterative Monte Carlo Method for \n",
    "Nonconjugate Bayesian Analysis, Statistics and Computing, 1, (2), 119\u0013â€ 128.\n",
    "\n",
    "Ratkowsky, D. (1983). Nonlinear regression modeling: A unified practical approach. M. Dekker, NY, viii, 276 p."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6594eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "X=   [    1.0  , 1.5  , 1.5  , 1.5  , 2.5  , 4.0  , 5.0  , 5.0  , 7.0 ,\n",
    "          8.0  , 8.5  , 9.0  , 9.5  , 9.5  , 10.0 , 12.0 , 12.0 , 13.0,\n",
    "          13.0 , 14.5 , 15.5 , 15.5 , 16.5 , 17.0 , 22.5 , 29.0 , 31.5]\n",
    "\n",
    "y=   [    1.8    , 1.85   , 1.87   , np.nan , 2.02   , 2.27   , 2.15   , 2.26   , 2.47,\n",
    "          2.19   , 2.26   , 2.4    , 2.39   , 2.41   , 2.5    , 2.32   , 2.32   , 2.43,  \n",
    "          2.47   , 2.56   , 2.65   , 2.47   , 2.64   , 2.56   , 2.7    , 2.72   , np.nan]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8506e24",
   "metadata": {},
   "source": [
    "The model is a nonlinear regression:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mu &\\sim \\mathcal{N}(\\alpha - \\beta \\cdot \\gamma^{\\mathbf{x}} , \\sigma^{2})\\\\\n",
    "\\alpha &\\sim \\mathcal{U}(0,100)\\\\\n",
    "\\beta &\\sim \\mathcal{U}(0,100)\\\\\n",
    "\\gamma &\\sim \\mathcal{U}(0,1)\\\\\n",
    "\\log\\{\\sigma\\} &\\sim \\mathcal{U}(-10,10)\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Note: $\\log(\\sigma)$ is modeled as a Uniform prior on [-10, 10]. We then exponentiate it to get sigma since PyMC requires standard deviation, not log-scale, for a Normal likelihood.\n",
    "\n",
    "The primary objective here is to observe how PyMC automatically treats the instances of `np.nan` in the observed data as unknown parameters.  The values of these unknown parameters are inferred alongside all other model parameters during sampling.\n",
    "\n",
    "PyMC imputes missing data automatically, similar to BUGS. \n",
    "\n",
    "It used to be that you needed to create a masked Numpy array, but this is no longer the case. It now detects NaN values passed into the observed argument and imputes them automatically. Note that this method only works for missing *observed* data. We'll learn about other types of missing data in Unit 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f18c8480",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aaron/miniforge3/envs/pymc_macos15/lib/python3.12/site-packages/pymc/model/core.py:1302: ImputationWarning: Data in likelihood contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [alpha, beta, gamma, sigma, likelihood_unobserved]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40d722d1fd0a455dbd2f2d4d55045040",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 5_000 draw iterations (4_000 + 20_000 draws total) took 8 seconds.\n",
      "There were 30 divergences after tuning. Increase `target_accept` or reparameterize.\n"
     ]
    }
   ],
   "source": [
    "with pm.Model() as m:\n",
    "    # priors\n",
    "    alpha = pm.Uniform(\"alpha\", 0, 100)\n",
    "    beta = pm.Uniform(\"beta\", 0, 100)\n",
    "    gamma = pm.Uniform(\"gamma\", 0, 1)\n",
    "    sigma = pm.math.exp(pm.Uniform(\"sigma\", -10, 10))\n",
    "\n",
    "    mu = alpha - beta * gamma**X\n",
    "\n",
    "    likelihood = pm.Normal(\"likelihood\", mu=mu, sigma=sigma, observed=y)\n",
    "\n",
    "    # start sampling\n",
    "    trace = pm.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50549805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>likelihood_unobserved[0]</th>\n",
       "      <td>1.905</td>\n",
       "      <td>0.111</td>\n",
       "      <td>1.694</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10455.0</td>\n",
       "      <td>10085.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>likelihood_unobserved[1]</th>\n",
       "      <td>2.697</td>\n",
       "      <td>0.127</td>\n",
       "      <td>2.446</td>\n",
       "      <td>2.945</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6013.0</td>\n",
       "      <td>4239.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>2.743</td>\n",
       "      <td>0.146</td>\n",
       "      <td>2.519</td>\n",
       "      <td>3.017</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>2198.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.994</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.791</td>\n",
       "      <td>1.218</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.002</td>\n",
       "      <td>4980.0</td>\n",
       "      <td>2841.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma</th>\n",
       "      <td>0.889</td>\n",
       "      <td>0.035</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.953</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>4174.0</td>\n",
       "      <td>2674.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sigma</th>\n",
       "      <td>-2.344</td>\n",
       "      <td>0.156</td>\n",
       "      <td>-2.648</td>\n",
       "      <td>-2.042</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.001</td>\n",
       "      <td>6996.0</td>\n",
       "      <td>7641.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean     sd  hdi_2.5%  hdi_97.5%  mcse_mean  \\\n",
       "likelihood_unobserved[0]  1.905  0.111     1.694      2.132      0.001   \n",
       "likelihood_unobserved[1]  2.697  0.127     2.446      2.945      0.002   \n",
       "alpha                     2.743  0.146     2.519      3.017      0.003   \n",
       "beta                      0.994  0.121     0.791      1.218      0.002   \n",
       "gamma                     0.889  0.035     0.818      0.953      0.000   \n",
       "sigma                    -2.344  0.156    -2.648     -2.042      0.002   \n",
       "\n",
       "                          mcse_sd  ess_bulk  ess_tail  r_hat  \n",
       "likelihood_unobserved[0]    0.001   10455.0   10085.0    1.0  \n",
       "likelihood_unobserved[1]    0.001    6013.0    4239.0    1.0  \n",
       "alpha                       0.002    4000.0    2198.0    1.0  \n",
       "beta                        0.002    4980.0    2841.0    1.0  \n",
       "gamma                       0.000    4174.0    2674.0    1.0  \n",
       "sigma                       0.001    6996.0    7641.0    1.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, hdi_prob=0.95, var_names=\"~likelihood\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a65dd1c",
   "metadata": {},
   "source": [
    "This output is very close to the BUGS results if you use the inits labeled Alternative (full) inits (initializing the missing values at 1):\n",
    "\n",
    "|           | mean    | sd      | MC_error | val2.5pc | median  | val97.5pc | start | sample |\n",
    "|-----------|---------|---------|----------|----------|---------|-----------|-------|--------|\n",
    "| alpha     | 2.731   | 0.1206  | 0.003167 | 2.551    | 2.711   | 3.025     | 1001  | 100000 |\n",
    "| beta      | 0.9846  | 0.1021  | 0.002008 | 0.8053   | 0.9773  | 1.212     | 1001  | 100000 |\n",
    "| gamma     | 0.8874  | 0.03381 | 7.64E-04 | 0.8124   | 0.8908  | 0.9427    | 1001  | 100000 |\n",
    "| log.sigma | -2.342  | 0.1543  | 7.83E-04 | -2.622   | -2.349  | -2.018    | 1001  | 100000 |\n",
    "| sigma     | 0.09733 | 0.0155  | 7.96E-05 | 0.07267  | 0.09547 | 0.1329    | 1001  | 100000 |\n",
    "| y[4]      | 1.906   | 0.1098  | 6.23E-04 | 1.689    | 1.906   | 2.123     | 1001  | 100000 |\n",
    "| y[27]     | 2.69    | 0.1255  | 0.001916 | 2.446    | 2.689   | 2.941     | 1001  | 100000 |\n",
    "\n",
    "\n",
    "If you use the first set of inits, as Professor Vidakovic did in the video, BUGS gives the y[4] mean as 2.047 and y[27] as 3.04. All the other variables are very different here, too. This is quite a mystery - as far as I can tell, the only difference is that the missing values use BUGS-generated inits for the following results. If someone figures out what's going on here, let me know!\n",
    "\n",
    "|       | mean   | sd       | MC_error | val2.5pc | median | val97.5pc | start | sample |\n",
    "|-------|--------|----------|----------|----------|--------|-----------|-------|--------|\n",
    "| alpha | 32.54  | 3.698    | 0.2076   | 23.51    | 32.69  | 40.31     | 1001  | 100000 |\n",
    "| beta  | 30.55  | 3.697    | 0.2076   | 21.52    | 30.69  | 38.31     | 1001  | 100000 |\n",
    "| gamma | 0.9989 | 2.08E-04 | 8.70E-06 | 0.9984   | 0.9989 | 0.9992    | 1001  | 100000 |\n",
    "| sigma | 0.1328 | 0.02071  | 8.17E-05 | 0.09964  | 0.1303 | 0.1805    | 1001  | 100000 |\n",
    "| y[4]  | 2.047  | 0.1424   | 5.18E-04 | 1.766    | 2.046  | 2.329     | 1001  | 100000 |\n",
    "| y[27] | 3.04   | 0.1606   | 7.42E-04 | 2.722    | 3.04   | 3.358     | 1001  | 100000 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "735609bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Last updated: Sun Mar 09 2025\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.12.7\n",
      "IPython version      : 8.29.0\n",
      "\n",
      "pytensor: 2.26.4\n",
      "\n",
      "numpy: 1.26.4\n",
      "pymc : 5.19.1\n",
      "arviz: 0.20.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -p pytensor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_macos15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
