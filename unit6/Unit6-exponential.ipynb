{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac97c902",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pymc as pm\n",
    "\n",
    "%load_ext lab_black\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d966cac4",
   "metadata": {},
   "source": [
    "# Bartholomew (1957) for Type I censoring\n",
    "\n",
    "This is our first introduction to censoring.\n",
    "\n",
    "It is adapted from [Codes for Unit 6: exponential1.odc](https://raw.githubusercontent.com/areding/6420-pymc/main/original_examples/Codes4Unit6/exponential1.odc).\n",
    "\n",
    "Dataset and table from: [A Problem in Life Testing (Bartholemew 1957)](https://www.jstor.org/stable/2280905?seq=1#metadata_info_tab_contents)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462585d",
   "metadata": {},
   "source": [
    "## Associated lecture video: Unit 6 Lesson 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d56f9d0",
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed?v=xomK4tcePmc&list=PLv0FeK5oXK4l-RdT6DWJj0_upJOG2WKNO&index=60\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed?v=xomK4tcePmc&list=PLv0FeK5oXK4l-RdT6DWJj0_upJOG2WKNO&index=60\" frameborder=\"0\" allow=\"autoplay; encrypted-media\" allowfullscreen></iframe>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32932c05",
   "metadata": {},
   "source": [
    "## Problem statement\n",
    "### Results of a life test on ten pieces of equipment\n",
    "|Item No.|1|2|3|4|5|6|7|8|9|10|\n",
    "|-|-|-|-|-|-|-|-|-|-|-|\n",
    "|Date of installation|11 June|21 June|22 June|2 July|21 July|31 July|31 July|1 Aug.|2 Aug.|10 Aug.|\n",
    "|Date of Failure|13 June| - | 12 Aug.| - |23 Aug.|27 Aug.|14 Aug.|25 Aug.|6 Aug.| - |\n",
    "|Life in Days|2|(119)|51|(77)|33|27|14|24|4|(37)|\n",
    "|No. Days to End of Period|81|72|70|60|41|31|31|30|29|21|\n",
    "\n",
    "The observations above are the result of a test on the lifespan of some piece of equipment. The test had to end on August 31, but items 2, 4, and 10 did not fail by that date (the values in parentheses are the eventual lifespans of those pieces of equipment, but they were not known on August 31). So all we know for the purposes of the experiment is that they worked for 72, 60, and 21 days, respectively, and that they will continue working for some unknown additional time period.\n",
    "\n",
    "The goal of the experiment is to provide a lifespan estimate. We could:\n",
    "\n",
    "1. Take the censored data as observed:\n",
    "    - Divide the total observed working time (308 days) and divide by the equipment count (10) to get an average lifetime of 308 for an estimate of 30.8 days.\n",
    "    - Problem: underestimates actual average lifespan.\n",
    "\n",
    "2. Ignore the equipment that didn't fail:\n",
    "    - Take mean lifetime of the pieces of equipment that broke within the experiment period for an estimate of 22.1 days.\n",
    "    - Problems: selection bias, underestimates even more.\n",
    "\n",
    "3. Use the classical method:\n",
    "    - Maximum Likelihood Estimation (MLE) under an exponential model. Total observed lifetime divided by 7 (number of observed failures) for an estimate of 44.0 days.\n",
    "    - Problem: small sample size.\n",
    "\n",
    "The actual mean lifespan of all pieces of equipment was 38.8 days.\n",
    "\n",
    "## A Bayesian approach\n",
    "We will right-censor the three machines that still hadn't failed by August 31, following [this example](https://docs.pymc.io/projects/examples/en/latest/generalized_linear_models/GLM-truncated-censored-regression.html#censored-regression-model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce659965",
   "metadata": {
    "tags": [
     "hide_output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [λ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='440000' class='' max='440000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [440000/440000 01:02<00:00 Sampling 4 chains, 0 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 10_000 tune and 100_000 draw iterations (40_000 + 400_000 draws total) took 87 seconds.\n"
     ]
    }
   ],
   "source": [
    "# gamma dist parameters\n",
    "α = 0.01\n",
    "β = 0.1\n",
    "\n",
    "# max possible observed life for each piece of equipment (before end of experiment)\n",
    "censored = (81, 72, 70, 60, 41, 31, 31, 30, 29, 21)\n",
    "\n",
    "# observed life within experiment dates\n",
    "y = (2, 72, 51, 60, 33, 27, 14, 24, 4, 21)\n",
    "\n",
    "\n",
    "with pm.Model() as m:\n",
    "    λ = pm.Gamma(\"λ\", α, β)\n",
    "    μ = pm.Deterministic(\"μ\", 1 / λ)\n",
    "    obs_latent = pm.Exponential.dist(λ)\n",
    "\n",
    "    observed = pm.Censored(\n",
    "        \"observed\", obs_latent, lower=None, upper=censored, observed=y, shape=len(y)\n",
    "    )\n",
    "\n",
    "    trace = pm.sample(\n",
    "        100000,\n",
    "        chains=4,\n",
    "        tune=10000,\n",
    "        cores=4,\n",
    "        init=\"jitter+adapt_diag\",\n",
    "        random_seed=1,\n",
    "        return_inferencedata=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "233c2f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_2.5%</th>\n",
       "      <th>hdi_97.5%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>λ</th>\n",
       "      <td>0.023</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174540.0</td>\n",
       "      <td>221610.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>μ</th>\n",
       "      <td>51.281</td>\n",
       "      <td>22.991</td>\n",
       "      <td>19.143</td>\n",
       "      <td>95.522</td>\n",
       "      <td>0.057</td>\n",
       "      <td>0.04</td>\n",
       "      <td>174540.0</td>\n",
       "      <td>221610.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean      sd  hdi_2.5%  hdi_97.5%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "λ   0.023   0.009     0.008      0.040      0.000     0.00  174540.0   \n",
       "μ  51.281  22.991    19.143     95.522      0.057     0.04  174540.0   \n",
       "\n",
       "   ess_tail  r_hat  \n",
       "λ  221610.0    1.0  \n",
       "μ  221610.0    1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.summary(trace, hdi_prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548f7ee8",
   "metadata": {},
   "source": [
    "BUGS results:\n",
    "\n",
    "|               |            mean | sd     | MC_error | val2.5pc | median  | val97.5pc | start | sample |\n",
    "|---------------|-----------------|--------|----------|----------|---------|-----------|-------|--------|\n",
    "| lambda        | 0.02281         | 0.0086 | 3.66E-05 | 0.009229 | 0.02169 | 0.04248   | 1001  | 100000 |\n",
    "| mu            | 51.07           | 22.61  | 0.1018   | 23.54    | 46.09   | 108.4     | 1001  | 100000 |\n",
    "| observed[2]   | 122.8           | 60.45  | 0.2442   | 73.12    | 103.5   | 284.5     | 1001  | 100000 |\n",
    "| observed[4]   | 110.8           | 59.93  | 0.2145   | 61.09    | 91.81   | 269.8     | 1001  | 100000 |\n",
    "| observed[10]  | 72.01           | 60.28  | 0.2155   | 22.13    | 52.89   | 232.6     | 1001  | 100000 |\n",
    "\n",
    "Okay, these results are pretty close. We end up with $1/.023=43.5$ days, compared to $43.8$ days for BUGS. But we're missing the imputed values for each censored observation. We could get those using the imputed censoring method in [this example](https://areding.github.io/6420-pymc/unit8/cens--gastric.html#method-2-imputed-censoring)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d9220bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.10.4\n",
      "IPython version      : 8.4.0\n",
      "\n",
      "arviz     : 0.12.1\n",
      "matplotlib: 3.5.2\n",
      "numpy     : 1.22.4\n",
      "pymc      : 4.0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark --iversions -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9ae04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
