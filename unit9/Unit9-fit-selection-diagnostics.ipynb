{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8120168f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 1. Model Fit, Selection, and Diagnostics\n",
    "\n",
    "\n",
    "## Deviance\n",
    "\n",
    "For model with likelihood $f(y|\\theta)$, deviance is given by\n",
    "\n",
    "$$ D(\\theta) = -2\\log(f(y|\\theta)) $$\n",
    "\n",
    "When comparing 2 models with deviance, the model with smaller deviance is better, in that it better fits the data. An alternate method for calculating deviance is\n",
    "\n",
    "$$ D_s(\\theta) = -2(\\log(f(y|\\theta)) - \\log(f(y|\\theta_s))) $$\n",
    "\n",
    "where $f(y|\\theta_s)$ is the *saturated* model, that is a model that perfectly fits the data. A few examples of saturated deviance are\n",
    "\n",
    "$$\\begin{align*}\n",
    " y_i \\sim Bin(n_i,\\theta_i): & \\space \\space D_s(\\underset{\\sim}{\\theta}) = \n",
    " 2 \\sum_i \\left ( y_i \\log \\frac{y_i/n_i}{\\theta_i} + (n_i - y_i)\\log \\frac{1-y_i/n_i}{1-\\theta_i} \\right ) \\\\\n",
    " y_i \\sim Poi(\\theta_i): & \\space \\space D_s(\\underset{\\sim}{\\theta}) = \n",
    " 2 \\sum_i \\left ( y_i \\log \\frac{y_i}{\\theta_i} - (y_i - \\theta_i) \\right ) \\\\\n",
    "  y_i \\sim N(\\theta_i,\\delta_i^2): & \\space \\space D_s(\\underset{\\sim}{\\theta}) = \n",
    " 2 \\sum_i \\left ( \\frac{y_i - \\theta_i}{\\delta_i} \\right ) ^2 \\\\\n",
    " \\end{align*}$$\n",
    "\n",
    "### Deviance example\n",
    "\n",
    "Consider 2 models, Weibull and Exponential, for the data\n",
    "\n",
    "$$ y = (1,1,2,2,3,4,4,5,5,8) $$\n",
    "\n",
    "with non-informative priors. Which model has the smaller deviance?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e3b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "import arviz as az\n",
    "import numpy as np\n",
    "\n",
    "y = np.array([1,1,2,2,3,4,4,5,5,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5462efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [mu, gamma]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5384aaf4b0cc4e568ea6ac9cfd80cc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 0 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deviance</th>\n",
       "      <td>42.911</td>\n",
       "      <td>2.121</td>\n",
       "      <td>40.869</td>\n",
       "      <td>46.741</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.126</td>\n",
       "      <td>984.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "deviance  42.911  2.121  40.869   46.741       0.08    0.126     984.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "deviance     906.0    1.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weibull Model\n",
    "with pm.Model() as m1:\n",
    "    #priors\n",
    "    mu = pm.Normal(\"mu\",0,tau=.001)\n",
    "    gamma = pm.Gamma(\"gamma\",0.001,0.001)\n",
    "\n",
    "    #convert Weibull parameterization\n",
    "    beta = gamma ** (-1 / mu)\n",
    "\n",
    "    #likelihood\n",
    "    like = pm.Weibull(\"like\",mu,beta,observed=y)\n",
    "\n",
    "    log_like = pm.math.log(mu*y**(mu-1)*pm.math.exp(-(y/beta)**mu)/(beta**mu))\n",
    "    deviance = pm.Deterministic(\"deviance\",-2*pm.math.sum(log_like))\n",
    "    \n",
    "    trace1 = pm.sample()\n",
    "\n",
    "az.summary(trace1,var_names=[\"deviance\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2dd80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing NUTS using jitter+adapt_diag...\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [lambda_]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26cb87529d4e4cc1ba033eb1a6507463",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 0 seconds.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>sd</th>\n",
       "      <th>hdi_3%</th>\n",
       "      <th>hdi_97%</th>\n",
       "      <th>mcse_mean</th>\n",
       "      <th>mcse_sd</th>\n",
       "      <th>ess_bulk</th>\n",
       "      <th>ess_tail</th>\n",
       "      <th>r_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>deviance</th>\n",
       "      <td>46.045</td>\n",
       "      <td>1.402</td>\n",
       "      <td>45.055</td>\n",
       "      <td>48.603</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.058</td>\n",
       "      <td>1864.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            mean     sd  hdi_3%  hdi_97%  mcse_mean  mcse_sd  ess_bulk  \\\n",
       "deviance  46.045  1.402  45.055   48.603      0.033    0.058    1864.0   \n",
       "\n",
       "          ess_tail  r_hat  \n",
       "deviance    2570.0    1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Exponential Model\n",
    "with pm.Model() as m2:\n",
    "    #prior\n",
    "    lambda_ = pm.Gamma(\"lambda_\",0.001,0.001)\n",
    "\n",
    "    #likelihood\n",
    "    like = pm.Exponential(\"like\",lambda_,observed=y)\n",
    "\n",
    "    log_like = pm.math.log(lambda_*pm.math.exp(-lambda_ * y))\n",
    "    deviance = pm.Deterministic(\"deviance\",-2*pm.math.sum(log_like))\n",
    "\n",
    "    trace2 = pm.sample()\n",
    "\n",
    "az.summary(trace2,var_names=\"deviance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbbec84-263e-433b-8b97-fd20e79f1197",
   "metadata": {},
   "source": [
    "We see the Weibull model has a lower deviance, and therefore fits the data better than the exponential model.\n",
    "\n",
    "## Extra\n",
    "\n",
    "Papers to check out:\n",
    "\n",
    "https://arxiv.org/abs/1307.5928\n",
    "\n",
    "https://arxiv.org/abs/1507.04544?context=stat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
